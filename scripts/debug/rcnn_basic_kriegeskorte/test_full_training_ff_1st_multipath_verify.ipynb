{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test full training of maskcnn_polished_with_rcnn_k_bl\n",
    "from os.path import join\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from thesis_v2 import dir_dict\n",
    "\n",
    "from thesis_v2.data.prepared.yuanyuan_8k import get_data\n",
    "\n",
    "from thesis_v2.training_extra.maskcnn_like.opt import get_maskcnn_v1_opt_config\n",
    "from thesis_v2.training_extra.maskcnn_like.training import (train_one,\n",
    "                                                            partial)\n",
    "\n",
    "from thesis_v2.models.maskcnn_polished_with_rcnn_k_bl.builder import (\n",
    "    gen_maskcnn_polished_with_rcnn_k_bl,\n",
    "    load_modules\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_maskcnn_polished_with_rcnn_k_bl(\n",
    "    split_seed,\n",
    "    model_seed,\n",
    "    act_fn,\n",
    "    loss_type,\n",
    "    input_size,\n",
    "    out_channel,\n",
    "    num_layer,\n",
    "    kernel_size_l1,\n",
    "    pooling_ksize,\n",
    "    scale, scale_name,\n",
    "    smoothness, smoothness_name,\n",
    "    pooling_type,\n",
    "    n_timesteps,\n",
    "):\n",
    "    \n",
    "    load_modules()\n",
    "    datasets = get_data('a', 200, input_size, ('042318', '043018', '051018'), scale=0.5,\n",
    "                        seed=split_seed)\n",
    "\n",
    "    datasets = {\n",
    "        'X_train': datasets[0].astype(np.float32),\n",
    "        'y_train': datasets[1],\n",
    "        'X_val': datasets[2].astype(np.float32),\n",
    "        'y_val': datasets[3],\n",
    "        'X_test': datasets[4].astype(np.float32),\n",
    "        'y_test': datasets[5],\n",
    "    }\n",
    "\n",
    "    def gen_cnn_partial(input_size_cnn, n):\n",
    "        return gen_maskcnn_polished_with_rcnn_k_bl(\n",
    "                                    input_size=input_size_cnn,\n",
    "                                    num_neuron=n,\n",
    "                                    out_channel=out_channel,\n",
    "                                    kernel_size_l1=kernel_size_l1,  # (try 5,9,13)\n",
    "                                    kernel_size_l23=3,\n",
    "                                    act_fn=act_fn,\n",
    "                                    pooling_ksize=pooling_ksize,  # (try, 1,3,5,7)\n",
    "                                    pooling_type=pooling_type,  # try (avg, max)  # looks that max works well here?\n",
    "                                    num_layer=num_layer,\n",
    "                                    n_timesteps=n_timesteps,\n",
    "                                    factored_constraint=None,\n",
    "                                    blstack_pool_ksize=1,\n",
    "                                    blstack_pool_type=None,\n",
    "                                    acc_mode='cummean',\n",
    "                                    bn_after_fc=False,\n",
    "                                    ff_1st_block=True,\n",
    "                                    )\n",
    "\n",
    "    opt_config_partial = partial(get_maskcnn_v1_opt_config,\n",
    "                                 scale=scale,\n",
    "                                 smoothness=smoothness,\n",
    "                                 group=0.0,\n",
    "                                 loss_type=loss_type,\n",
    "                                 )\n",
    "    \n",
    "    result = train_one(\n",
    "        arch_json_partial=gen_cnn_partial,\n",
    "        opt_config_partial=opt_config_partial,\n",
    "        datasets=datasets,\n",
    "        key=f'debug/test_full_training_maskcnn_polished_with_rcnn_k_bl/ff_1st_block_multipath/{model_seed}',\n",
    "        show_every=100,\n",
    "        max_epoch=40000,\n",
    "        model_seed=model_seed,\n",
    "        return_model=False,\n",
    "        extra_params={\n",
    "            # reduce on batch axis\n",
    "            'eval_fn': {\n",
    "                'yhat_reduce_axis': 1,\n",
    "            }\n",
    "        },\n",
    "        print_model=True\n",
    "    )\n",
    "    \n",
    "    return result['stats_best']['stats']['test']['corr_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'final_act', 'fc', 'bn_output', 'pooling'}\n",
      "['conv0', 'bl_stack.layer_list.0.b_conv', 'bl_stack.layer_list.1.b_conv']\n",
      "num_param 27629\n",
      "JSONNet(\n",
      "  (moduledict): ModuleDict(\n",
      "    (accumulator): RecurrentAccumulator()\n",
      "    (act0): ReLU()\n",
      "    (bl_stack): BLConvLayerStack(\n",
      "      (layer_list): ModuleList(\n",
      "        (0): BLConvLayer(\n",
      "          (b_conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (l_conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (1): BLConvLayer(\n",
      "          (b_conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (l_conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bn_layer_list): ModuleList(\n",
      "        (0): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (capture_list): ModuleList(\n",
      "        (0): Identity()\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (input_capture): Identity()\n",
      "      (act_fn): ReLU(inplace=True)\n",
      "      (pool): Identity()\n",
      "    )\n",
      "    (bn0): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn_input): BatchNorm2d(1, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv0): Conv2d(1, 16, kernel_size=(9, 9), stride=(1, 1), bias=False)\n",
      "    (fc): FactoredLinear2D(map_size=(14, 14), out_features=79, weight_feature_constraint=None, weight_spatial_constraint=None, bias=True)\n",
      "    (final_act): ReLU()\n",
      "    (pooling): AvgPool2d(kernel_size=3, stride=3, padding=0)\n",
      "  )\n",
      ")\n",
      "num of phase:  3\n",
      "0.5305084970028694\n"
     ]
    }
   ],
   "source": [
    "maskcnn_param_template = {\n",
    "    'out_channel': 16,\n",
    "    'num_layer': 3,\n",
    "    'kernel_size_l1': 9,\n",
    "    'pooling_ksize': 3,\n",
    "    'pooling_type': 'avg',\n",
    "    'model_seed': 0,\n",
    "    'split_seed': 'legacy',\n",
    "}\n",
    "\n",
    "maskcnn_param_regular = {\n",
    "    **maskcnn_param_template,\n",
    "    **{\n",
    "        'act_fn': 'relu',\n",
    "        'loss_type': 'mse',\n",
    "        'smoothness': 0.000005,\n",
    "        'smoothness_name': '0.000005',\n",
    "        'scale': 0.01,\n",
    "        'scale_name': '0.01',\n",
    "        'input_size': 50,\n",
    "        'n_timesteps': 4,\n",
    "    }\n",
    "}\n",
    "\n",
    "print(train_one_maskcnn_polished_with_rcnn_k_bl(**maskcnn_param_regular))\n",
    "\n",
    "# 27629 = 1*2 + 16*1*9*9 + 16*2 + 2*(16*16*3*3+16*16*3*3+4*16*2) + 79*(14*14 + 16 + 1) \n",
    "\n",
    "# results here are exactly the same as those in `scripts/debug/rcnn_basic_kriegeskorte/test_full_training_ff_1st.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, no_grad, float32, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then let's make sure that my multi-path ensemble is implemented correctly.\n",
    "\n",
    "# at least, when all bias is zero, and there is NO activation function, and there is no duplication of BN layer,\n",
    "# multi path should give exactly the same result as original model\n",
    "\n",
    "def check_result(multi_path):\n",
    "    \n",
    "    \n",
    "    \n",
    "    key = 'debug/test_full_training_maskcnn_polished_with_rcnn_k_bl/ff_1st_block_multipath/0'\n",
    "    def gen_cnn_partial(input_size_cnn, n):\n",
    "        return gen_maskcnn_polished_with_rcnn_k_bl(\n",
    "                                    input_size=input_size_cnn,\n",
    "                                    num_neuron=n,\n",
    "                                    out_channel=maskcnn_param_regular['out_channel'],\n",
    "                                    kernel_size_l1=maskcnn_param_regular['kernel_size_l1'],  # (try 5,9,13)\n",
    "                                    kernel_size_l23=3,\n",
    "                                    act_fn=maskcnn_param_regular['act_fn'],\n",
    "                                    pooling_ksize=maskcnn_param_regular['pooling_ksize'],  # (try, 1,3,5,7)\n",
    "                                    pooling_type=maskcnn_param_regular['pooling_type'],  # try (avg, max)  # looks that max works well here?\n",
    "                                    num_layer=maskcnn_param_regular['num_layer'],\n",
    "                                    n_timesteps=maskcnn_param_regular['n_timesteps'],\n",
    "                                    factored_constraint=None,\n",
    "                                    blstack_pool_ksize=1,\n",
    "                                    blstack_pool_type=None,\n",
    "                                    acc_mode='cummean',\n",
    "                                    bn_after_fc=False,\n",
    "                                    ff_1st_block=True,\n",
    "            act_fn_inner=None,  # no act for innner blocks\n",
    "            ff_1st_bn_before_act=None,\n",
    "            multi_path=multi_path,\n",
    "            multi_path_separate_bn=False if multi_path else None\n",
    "                                    )\n",
    "    model_json = gen_cnn_partial(50, 79)\n",
    "    model_this = load_training_results(key, return_model=True, model=build_net(model_json))['model']\n",
    "    model_this.eval()\n",
    "    print(model_this)\n",
    "    print(model_this.get_module('bl_stack').multi_path, model_this.get_module('bl_stack').multi_path_separate_bn)\n",
    "    \n",
    "    \n",
    "    for name, mod in model_this.named_modules():\n",
    "        # all bias parameters will duplicate their effects in the multi chain analysis.\n",
    "        if isinstance(mod, nn.BatchNorm2d):\n",
    "            print(name)\n",
    "            with no_grad():\n",
    "                mod.bias.zero_()\n",
    "                mod.running_mean.zero_()\n",
    "    \n",
    "    # pass in some images and see the response\n",
    "    rng_state = np.random.RandomState(seed=0)\n",
    "    with no_grad():\n",
    "        images = tensor(rng_state.rand(10, 1, 50, 50)*255, dtype=float32)\n",
    "        responses = model_this(images)\n",
    "        assert len(responses) == 1\n",
    "        responses = responses[0].numpy()\n",
    "    \n",
    "    return responses\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'final_act', 'fc', 'bn_output', 'pooling'}\n",
      "JSONNet(\n",
      "  (moduledict): ModuleDict(\n",
      "    (accumulator): RecurrentAccumulator()\n",
      "    (bl_stack): BLConvLayerStack(\n",
      "      (layer_list): ModuleList(\n",
      "        (0): BLConvLayer(\n",
      "          (b_conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (l_conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (1): BLConvLayer(\n",
      "          (b_conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (l_conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bn_layer_list): ModuleList(\n",
      "        (0): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (capture_list): ModuleList(\n",
      "        (0): Identity()\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (input_capture): Identity()\n",
      "      (act_fn): Identity()\n",
      "      (pool): Identity()\n",
      "    )\n",
      "    (bn0): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn_input): BatchNorm2d(1, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv0): Conv2d(1, 16, kernel_size=(9, 9), stride=(1, 1), bias=False)\n",
      "    (fc): FactoredLinear2D(map_size=(14, 14), out_features=79, weight_feature_constraint=None, weight_spatial_constraint=None, bias=True)\n",
      "    (final_act): ReLU()\n",
      "    (pooling): AvgPool2d(kernel_size=3, stride=3, padding=0)\n",
      "  )\n",
      ")\n",
      "False None\n",
      "moduledict.bl_stack.bn_layer_list.0\n",
      "moduledict.bl_stack.bn_layer_list.1\n",
      "moduledict.bl_stack.bn_layer_list.2\n",
      "moduledict.bl_stack.bn_layer_list.3\n",
      "moduledict.bl_stack.bn_layer_list.4\n",
      "moduledict.bl_stack.bn_layer_list.5\n",
      "moduledict.bl_stack.bn_layer_list.6\n",
      "moduledict.bl_stack.bn_layer_list.7\n",
      "moduledict.bn0\n",
      "moduledict.bn_input\n"
     ]
    }
   ],
   "source": [
    "from thesis_v2.training.training_aux import load_training_results\n",
    "from torchnetjson.builder import build_net\n",
    "\n",
    "resp_old = check_result(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'final_act', 'fc', 'bn_output', 'pooling'}\n",
      "JSONNet(\n",
      "  (moduledict): ModuleDict(\n",
      "    (accumulator): RecurrentAccumulator()\n",
      "    (bl_stack): BLConvLayerStack(\n",
      "      (layer_list): ModuleList(\n",
      "        (0): BLConvLayer(\n",
      "          (b_conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (l_conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (1): BLConvLayer(\n",
      "          (b_conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (l_conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bn_layer_list): ModuleList(\n",
      "        (0): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (capture_list): ModuleList(\n",
      "        (0): Identity()\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (input_capture): Identity()\n",
      "      (act_fn): Identity()\n",
      "      (pool): Identity()\n",
      "    )\n",
      "    (bn0): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn_input): BatchNorm2d(1, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv0): Conv2d(1, 16, kernel_size=(9, 9), stride=(1, 1), bias=False)\n",
      "    (fc): FactoredLinear2D(map_size=(14, 14), out_features=79, weight_feature_constraint=None, weight_spatial_constraint=None, bias=True)\n",
      "    (final_act): ReLU()\n",
      "    (pooling): AvgPool2d(kernel_size=3, stride=3, padding=0)\n",
      "  )\n",
      ")\n",
      "True False\n",
      "moduledict.bl_stack.bn_layer_list.0\n",
      "moduledict.bl_stack.bn_layer_list.1\n",
      "moduledict.bl_stack.bn_layer_list.2\n",
      "moduledict.bl_stack.bn_layer_list.3\n",
      "moduledict.bl_stack.bn_layer_list.4\n",
      "moduledict.bl_stack.bn_layer_list.5\n",
      "moduledict.bl_stack.bn_layer_list.6\n",
      "moduledict.bl_stack.bn_layer_list.7\n",
      "moduledict.bn0\n",
      "moduledict.bn_input\n"
     ]
    }
   ],
   "source": [
    "resp_new = check_result(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 10, 79)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 10, 79)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_old.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert resp_new.shape == resp_old.shape\n",
    "assert np.allclose(resp_new, resp_old, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.close('all')\n",
    "plt.hist(resp_old.ravel()-resp_new.ravel(), bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('yimeng')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "70011ff74c3ba96f39381fbde7368c6908ed277a867b24ef9cfcee03103b0f30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
