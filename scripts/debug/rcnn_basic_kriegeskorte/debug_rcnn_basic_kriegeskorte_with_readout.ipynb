{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to test my `torchnetjson` (`JSONNet`) framework to generate the basic RCNN plus a readout, just as in `maskcnn_polished` and `maskcnn_polished_with_local_pcn`. I did this so that to make sure I can generate the `builder` files for this network easily. `builder` files are required for network training in my thesis codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import tensor, no_grad, Tensor\n",
    "\n",
    "from thesis_v2.blocks.rcnn_basic_kriegeskorte import nn_modules\n",
    "from thesis_v2.blocks import load_modules\n",
    "from thesis_v2.blocks_json.utils import new_map_size\n",
    "from thesis_v2.blocks_json import maskcnn, pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random_img = np.random.random_sample((10, 50, 50, 1))*2 - 1\n",
    "random_img = random_img.astype(np.float32)\n",
    "random_img = random_img.transpose((0,3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# a = nn_modules.BLConvLayerStack(\n",
    "#     n_timesteps=8,\n",
    "#     channel_list=[3,96,128,192,256,512,1024,2048],\n",
    "#     ksize_list=[7,5,3,3,3,3,1],\n",
    "#     # matching tf's bn config.\n",
    "#     bn_eps=0.001,\n",
    "# )\n",
    "\n",
    "from torch import tensor\n",
    "from torchnetjson.builder import build_net\n",
    "\n",
    "load_modules([\n",
    "    'rcnn_kriegeskorte.blstack',\n",
    "    'rcnn_kriegeskorte.accumulator',\n",
    "    'maskcnn.factoredfc',\n",
    "])\n",
    "\n",
    "def build_test_net(out, *,\n",
    "                   input_size=(50,50),\n",
    "                   have_readout=False,\n",
    "                  ):\n",
    "    input_size_dict = {\n",
    "        'map_size': input_size,\n",
    "    }\n",
    "    module_dict = {\n",
    "        'stack': {\n",
    "            'name':'rcnn_kriegeskorte.blstack',\n",
    "            'params': {\n",
    "                'n_timesteps': 8,\n",
    "                'channel_list': [1,32,16],\n",
    "                'ksize_list': [7,3],\n",
    "                # no pooling.\n",
    "                'pool_ksize': 1,\n",
    "            },\n",
    "            'init': {\n",
    "                'strategy': 'normal',\n",
    "                'parameters': {'std': 0.5}\n",
    "            }\n",
    "        },\n",
    "        'accumulator_cummean': {\n",
    "            'name': 'rcnn_kriegeskorte.accumulator',\n",
    "            'params': {'mode': 'cummean'},\n",
    "            'init': None,\n",
    "        },\n",
    "        **pooling.pool2d(\n",
    "            name='pooling',\n",
    "             pooling_type='max',\n",
    "             kernel_size=2,\n",
    "             input_size=input_size_dict['map_size'],\n",
    "             state_dict=input_size_dict,\n",
    "             ceil_mode=False,\n",
    "             map_size_strict=True\n",
    "        ),\n",
    "        **maskcnn.factoredfc(\n",
    "            name='fc',\n",
    "            map_size=input_size_dict['map_size'],\n",
    "            in_channels=16,\n",
    "            out_features=5,\n",
    "            bias=True,\n",
    "            weight_spatial_constraint=None,\n",
    "            weight_feature_constraint=None,\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # because this whole network uses `same` padding, in TF jargon and no pooling.\n",
    "    map_size = input_size\n",
    "    \n",
    "    intermediate_name = 'inter_unused'\n",
    "\n",
    "    op_list = [\n",
    "        {'name': 'module',\n",
    "         'args': ['stack'],\n",
    "         'kwargs': {},\n",
    "         'in': 'input0',\n",
    "         'out': 'out_raw',\n",
    "        },\n",
    "        {'name': 'module',\n",
    "         'args': ['accumulator_cummean'],\n",
    "         'kwargs': {\n",
    "             'unpack': False,\n",
    "         },\n",
    "         'in': 'out_raw',\n",
    "         'out': 'out_cummean',\n",
    "        },\n",
    "        # then apply pooling to `out_cummean`, using `module_repeat` op.\n",
    "        {'name': 'module_repeat',\n",
    "         'args': ['pooling'],\n",
    "         'kwargs': {},\n",
    "         'in': 'out_cummean',\n",
    "         'out': intermediate_name,\n",
    "        },\n",
    "        {'name': 'module_repeat',\n",
    "         'args': ['fc'],\n",
    "         'kwargs': {},\n",
    "         'in': intermediate_name,\n",
    "         'out': 'fc_out',\n",
    "        },\n",
    "        # finally, combine all timesteps' data into one chunk.\n",
    "        {\n",
    "            'name': 'stack',\n",
    "            'args': [],\n",
    "            'kwargs': {'dim': 0},\n",
    "            'in': 'fc_out',\n",
    "            'out': 'combined',\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    param_dict = {\n",
    "        'module_dict': module_dict,\n",
    "        'op_list': op_list,\n",
    "        # change out to fit your needs.\n",
    "        'out': out,\n",
    "    }\n",
    "\n",
    "    return build_net(param_dict)\n",
    "\n",
    "\n",
    "a = build_test_net('combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moduledict.fc.weight_spatial torch.Size([5, 25, 25]) tensor(-0.0003) tensor(0.0101)\n",
      "moduledict.fc.weight_feature torch.Size([5, 16]) tensor(0.0005) tensor(0.0087)\n",
      "moduledict.fc.bias torch.Size([5]) tensor(0.) tensor(0.)\n",
      "moduledict.stack.layer_list.0.b_conv.weight torch.Size([32, 1, 7, 7]) tensor(0.0181) tensor(0.5002)\n",
      "moduledict.stack.layer_list.0.l_conv.weight torch.Size([32, 32, 7, 7]) tensor(0.0004) tensor(0.4988)\n",
      "moduledict.stack.layer_list.1.b_conv.weight torch.Size([16, 32, 3, 3]) tensor(-0.0094) tensor(0.4957)\n",
      "moduledict.stack.layer_list.1.l_conv.weight torch.Size([16, 16, 3, 3]) tensor(0.0148) tensor(0.4911)\n",
      "moduledict.stack.bn_layer_list.0.weight torch.Size([32]) tensor(1.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.0.bias torch.Size([32]) tensor(0.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.1.weight torch.Size([16]) tensor(1.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.1.bias torch.Size([16]) tensor(0.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.2.weight torch.Size([32]) tensor(1.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.2.bias torch.Size([32]) tensor(0.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.3.weight torch.Size([16]) tensor(1.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.3.bias torch.Size([16]) tensor(0.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.4.weight torch.Size([32]) tensor(1.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.4.bias torch.Size([32]) tensor(0.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.5.weight torch.Size([16]) tensor(1.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.5.bias torch.Size([16]) tensor(0.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.6.weight torch.Size([32]) tensor(1.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.6.bias torch.Size([32]) tensor(0.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.7.weight torch.Size([16]) tensor(1.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.7.bias torch.Size([16]) tensor(0.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.8.weight torch.Size([32]) tensor(1.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.8.bias torch.Size([32]) tensor(0.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.9.weight torch.Size([16]) tensor(1.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.9.bias torch.Size([16]) tensor(0.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.10.weight torch.Size([32]) tensor(1.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.10.bias torch.Size([32]) tensor(0.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.11.weight torch.Size([16]) tensor(1.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.11.bias torch.Size([16]) tensor(0.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.12.weight torch.Size([32]) tensor(1.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.12.bias torch.Size([32]) tensor(0.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.13.weight torch.Size([16]) tensor(1.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.13.bias torch.Size([16]) tensor(0.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.14.weight torch.Size([32]) tensor(1.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.14.bias torch.Size([32]) tensor(0.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.15.weight torch.Size([16]) tensor(1.) tensor(0.)\n",
      "moduledict.stack.bn_layer_list.15.bias torch.Size([16]) tensor(0.) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "def check_build_net_params(net_to_check):\n",
    "    with no_grad():\n",
    "        for x, y in net_to_check.named_parameters():\n",
    "            print(x, y.size(), y.mean(), y.std())\n",
    "        \n",
    "# looks good. for conv kernels, mean should be 0, std should be 0.5,\n",
    "# for bn parameters, weight should all be 1, bias should all be 0.\n",
    "# for fc layer parameters, should have zero mean and std of 0.01 (the default value)\n",
    "check_build_net_params(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.cuda.FloatTensor\n",
      "torch.Size([10, 5])\n",
      "torch.Size([10, 5])\n",
      "torch.Size([10, 5])\n",
      "torch.Size([10, 5])\n",
      "torch.Size([10, 5])\n",
      "torch.Size([10, 5])\n",
      "torch.Size([10, 5])\n",
      "torch.Size([10, 5])\n"
     ]
    }
   ],
   "source": [
    "# let's put some test data.\n",
    "a.cuda().eval()\n",
    "\n",
    "with no_grad():\n",
    "    out_this = a(tensor(random_img).cuda())\n",
    "    print(type(out_this))\n",
    "#     print(Tensor)\n",
    "    \n",
    "    if isinstance(out_this, Tensor):\n",
    "        print(out_this.type())\n",
    "    for x in out_this:\n",
    "        print(x.size())\n",
    "        \n",
    "# also tried a = build_test_net('inter_unused'), get eight torch.Size([10, 16, 25, 25]), as expected.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
