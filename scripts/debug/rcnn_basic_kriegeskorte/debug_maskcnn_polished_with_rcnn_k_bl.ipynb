{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import tensor, no_grad, Tensor\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from thesis_v2.models.maskcnn_polished_with_rcnn_k_bl.builder import (\n",
    "    gen_maskcnn_polished_with_rcnn_k_bl, load_modules\n",
    ")\n",
    "\n",
    "load_modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random_img = np.random.random_sample((10, 50, 50, 1))*2 - 1\n",
    "random_img = random_img.astype(np.float32)\n",
    "random_img = random_img.transpose((0,3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torchnetjson.builder import build_net\n",
    "\n",
    "def make_model(\n",
    "    *,\n",
    "    n_timesteps,\n",
    "    acc_mode,\n",
    "    pooling_ksize,\n",
    "    debug_args=None,\n",
    "):\n",
    "    model_json = gen_maskcnn_polished_with_rcnn_k_bl(\n",
    "        (50, 50), 3,\n",
    "        n_timesteps=n_timesteps,\n",
    "        acc_mode=acc_mode,\n",
    "        pooling_ksize=pooling_ksize,\n",
    "        debug_args=debug_args,\n",
    "    )\n",
    "    print(json.dumps(model_json, indent=2))\n",
    "    torch.manual_seed(0)\n",
    "    model = build_net(model_json)\n",
    "\n",
    "    with no_grad():\n",
    "        for x, y in model.named_parameters():\n",
    "            print(x, y.size(), y.mean(), y.std())\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.backends import cudnn\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# let's put some test data.\n",
    "def eval_model(model_to_eval, check=True):\n",
    "    model_to_eval.cuda().eval()\n",
    "\n",
    "    with no_grad():\n",
    "        out_this = model_to_eval(tensor(random_img).cuda())\n",
    "        if check:\n",
    "            assert type(out_this) is tuple and len(out_this) == 1\n",
    "    \n",
    "    if check:\n",
    "        print(out_this[0].size())\n",
    "        return out_this[0].detach().cpu().numpy()\n",
    "    else:\n",
    "        return out_this\n",
    "\n",
    "\n",
    "def check_ff():\n",
    "    model_a = make_model(\n",
    "        n_timesteps=1,\n",
    "        acc_mode='instant',\n",
    "        pooling_ksize=2,\n",
    "    )\n",
    "    model_b = make_model(\n",
    "        n_timesteps=1,\n",
    "        acc_mode='cummean',\n",
    "        pooling_ksize=2,\n",
    "    )\n",
    "    out_a = eval_model(model_a)\n",
    "    out_b = eval_model(model_b)\n",
    "    \n",
    "    assert np.array_equal(out_a, out_b)\n",
    "\n",
    "    \n",
    "def check_instant_vs_cummean():\n",
    "    model_a = make_model(\n",
    "        n_timesteps=8,\n",
    "        acc_mode='instant',\n",
    "        pooling_ksize=1,\n",
    "        debug_args={'only_fc': True}\n",
    "    )\n",
    "    model_b = make_model(\n",
    "        n_timesteps=8,\n",
    "        acc_mode='cummean',\n",
    "        pooling_ksize=1,\n",
    "        debug_args={'only_fc': True}\n",
    "    )\n",
    "    out_a = eval_model(model_a)\n",
    "    out_b = eval_model(model_b)\n",
    "    \n",
    "    assert out_a.shape == out_b.shape == (8, 10, 3)\n",
    "    \n",
    "    for idx in range(8):\n",
    "        instant_out = np.mean(out_a[:idx+1], axis=0)\n",
    "        cummean_out = out_b[idx]\n",
    "        assert instant_out.shape == cummean_out.shape == (10,3)\n",
    "        print(instant_out.mean(), instant_out.std())\n",
    "        print(cummean_out.mean(), cummean_out.std())\n",
    "        assert np.allclose(instant_out, cummean_out, atol=1e-5)\n",
    "\n",
    "def check_stack_vs_no_stack():\n",
    "    model_a = make_model(\n",
    "        n_timesteps=8,\n",
    "        acc_mode='cummean',\n",
    "        pooling_ksize=2,\n",
    "    )\n",
    "    model_b = make_model(\n",
    "        n_timesteps=8,\n",
    "        acc_mode='cummean',\n",
    "        pooling_ksize=2,\n",
    "        debug_args={'stack': False}\n",
    "    )\n",
    "    \n",
    "    out_a = eval_model(model_a, check=False)\n",
    "    out_b = eval_model(model_b, check=False)\n",
    "    out_a = out_a[0].detach().cpu().numpy()\n",
    "    out_b = [x.detach().cpu().numpy() for x in out_b]\n",
    "    assert out_a.shape == (8, 10, 3)\n",
    "    assert np.array_equal(out_a, np.asarray(out_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pooling', 'final_act', 'bn_output', 'fc'}\n",
      "{\n",
      "  \"module_dict\": {\n",
      "    \"bn_input\": {\n",
      "      \"name\": \"torch.nn.batchnorm2d\",\n",
      "      \"params\": {\n",
      "        \"num_features\": 1,\n",
      "        \"eps\": 0.001,\n",
      "        \"momentum\": 0.1,\n",
      "        \"affine\": true\n",
      "      },\n",
      "      \"init\": {}\n",
      "    },\n",
      "    \"bl_stack\": {\n",
      "      \"name\": \"rcnn_kriegeskorte.blstack\",\n",
      "      \"params\": {\n",
      "        \"n_timesteps\": 1,\n",
      "        \"channel_list\": [\n",
      "          1,\n",
      "          48,\n",
      "          48,\n",
      "          48\n",
      "        ],\n",
      "        \"ksize_list\": [\n",
      "          13,\n",
      "          3,\n",
      "          3\n",
      "        ],\n",
      "        \"pool_ksize\": 1,\n",
      "        \"act_fn\": \"softplus\"\n",
      "      },\n",
      "      \"init\": {\n",
      "        \"strategy\": \"normal\",\n",
      "        \"parameters\": {\n",
      "          \"std\": 0.01\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"accumulator\": {\n",
      "      \"name\": \"rcnn_kriegeskorte.accumulator\",\n",
      "      \"params\": {\n",
      "        \"mode\": \"instant\"\n",
      "      },\n",
      "      \"init\": null\n",
      "    },\n",
      "    \"pooling\": {\n",
      "      \"name\": \"torch.nn.maxpool2d\",\n",
      "      \"params\": {\n",
      "        \"kernel_size\": 2,\n",
      "        \"ceil_mode\": true\n",
      "      },\n",
      "      \"init\": null\n",
      "    },\n",
      "    \"fc\": {\n",
      "      \"name\": \"maskcnn.factoredfc\",\n",
      "      \"params\": {\n",
      "        \"in_channels\": 48,\n",
      "        \"map_size\": [\n",
      "          25,\n",
      "          25\n",
      "        ],\n",
      "        \"out_features\": 3,\n",
      "        \"bias\": true,\n",
      "        \"weight_feature_constraint\": null,\n",
      "        \"weight_spatial_constraint\": null\n",
      "      },\n",
      "      \"init\": {\n",
      "        \"strategy\": \"normal\",\n",
      "        \"parameters\": {\n",
      "          \"std\": 0.01\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"final_act\": {\n",
      "      \"name\": \"torch.nn.softplus\",\n",
      "      \"params\": {},\n",
      "      \"init\": null\n",
      "    }\n",
      "  },\n",
      "  \"op_list\": [\n",
      "    {\n",
      "      \"name\": \"sequential\",\n",
      "      \"args\": [\n",
      "        [\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"bn_input\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"bl_stack\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"accumulator\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      ],\n",
      "      \"kwargs\": {},\n",
      "      \"in\": \"input0\",\n",
      "      \"out\": \"feature_map\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"sequential\",\n",
      "      \"args\": [\n",
      "        [\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"pooling\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"fc\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"final_act\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          }\n",
      "        ]\n",
      "      ],\n",
      "      \"kwargs\": {},\n",
      "      \"in\": \"feature_map\",\n",
      "      \"out\": \"out_neural_separate\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"stack\",\n",
      "      \"args\": [],\n",
      "      \"kwargs\": {\n",
      "        \"dim\": 0\n",
      "      },\n",
      "      \"in\": \"out_neural_separate\",\n",
      "      \"out\": \"out_neural\"\n",
      "    }\n",
      "  ],\n",
      "  \"out\": [\n",
      "    \"out_neural\"\n",
      "  ],\n",
      "  \"comments\": {\n",
      "    \"conv_layers\": [\n",
      "      \"stack.layer_list.0.b_conv\",\n",
      "      \"stack.layer_list.1.b_conv\",\n",
      "      \"stack.layer_list.2.b_conv\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "moduledict.bl_stack.layer_list.0.b_conv.weight torch.Size([48, 1, 13, 13]) tensor(1.0089e-05) tensor(0.0099)\n",
      "moduledict.bl_stack.layer_list.1.b_conv.weight torch.Size([48, 48, 3, 3]) tensor(9.8976e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.2.b_conv.weight torch.Size([48, 48, 3, 3]) tensor(-4.3671e-05) tensor(0.0101)\n",
      "moduledict.bl_stack.bn_layer_list.0.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.0.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.1.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.1.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.2.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.2.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bn_input.weight torch.Size([1]) tensor(1.) tensor(nan)\n",
      "moduledict.bn_input.bias torch.Size([1]) tensor(0.) tensor(nan)\n",
      "moduledict.fc.weight_spatial torch.Size([3, 25, 25]) tensor(-5.5713e-05) tensor(0.0098)\n",
      "moduledict.fc.weight_feature torch.Size([3, 48]) tensor(0.0009) tensor(0.0099)\n",
      "moduledict.fc.bias torch.Size([3]) tensor(0.) tensor(0.)\n",
      "{'pooling', 'final_act', 'bn_output', 'fc'}\n",
      "{\n",
      "  \"module_dict\": {\n",
      "    \"bn_input\": {\n",
      "      \"name\": \"torch.nn.batchnorm2d\",\n",
      "      \"params\": {\n",
      "        \"num_features\": 1,\n",
      "        \"eps\": 0.001,\n",
      "        \"momentum\": 0.1,\n",
      "        \"affine\": true\n",
      "      },\n",
      "      \"init\": {}\n",
      "    },\n",
      "    \"bl_stack\": {\n",
      "      \"name\": \"rcnn_kriegeskorte.blstack\",\n",
      "      \"params\": {\n",
      "        \"n_timesteps\": 1,\n",
      "        \"channel_list\": [\n",
      "          1,\n",
      "          48,\n",
      "          48,\n",
      "          48\n",
      "        ],\n",
      "        \"ksize_list\": [\n",
      "          13,\n",
      "          3,\n",
      "          3\n",
      "        ],\n",
      "        \"pool_ksize\": 1,\n",
      "        \"act_fn\": \"softplus\"\n",
      "      },\n",
      "      \"init\": {\n",
      "        \"strategy\": \"normal\",\n",
      "        \"parameters\": {\n",
      "          \"std\": 0.01\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"accumulator\": {\n",
      "      \"name\": \"rcnn_kriegeskorte.accumulator\",\n",
      "      \"params\": {\n",
      "        \"mode\": \"cummean\"\n",
      "      },\n",
      "      \"init\": null\n",
      "    },\n",
      "    \"pooling\": {\n",
      "      \"name\": \"torch.nn.maxpool2d\",\n",
      "      \"params\": {\n",
      "        \"kernel_size\": 2,\n",
      "        \"ceil_mode\": true\n",
      "      },\n",
      "      \"init\": null\n",
      "    },\n",
      "    \"fc\": {\n",
      "      \"name\": \"maskcnn.factoredfc\",\n",
      "      \"params\": {\n",
      "        \"in_channels\": 48,\n",
      "        \"map_size\": [\n",
      "          25,\n",
      "          25\n",
      "        ],\n",
      "        \"out_features\": 3,\n",
      "        \"bias\": true,\n",
      "        \"weight_feature_constraint\": null,\n",
      "        \"weight_spatial_constraint\": null\n",
      "      },\n",
      "      \"init\": {\n",
      "        \"strategy\": \"normal\",\n",
      "        \"parameters\": {\n",
      "          \"std\": 0.01\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"final_act\": {\n",
      "      \"name\": \"torch.nn.softplus\",\n",
      "      \"params\": {},\n",
      "      \"init\": null\n",
      "    }\n",
      "  },\n",
      "  \"op_list\": [\n",
      "    {\n",
      "      \"name\": \"sequential\",\n",
      "      \"args\": [\n",
      "        [\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"bn_input\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"bl_stack\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"accumulator\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      ],\n",
      "      \"kwargs\": {},\n",
      "      \"in\": \"input0\",\n",
      "      \"out\": \"feature_map\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"sequential\",\n",
      "      \"args\": [\n",
      "        [\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"pooling\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"fc\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"final_act\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          }\n",
      "        ]\n",
      "      ],\n",
      "      \"kwargs\": {},\n",
      "      \"in\": \"feature_map\",\n",
      "      \"out\": \"out_neural_separate\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"stack\",\n",
      "      \"args\": [],\n",
      "      \"kwargs\": {\n",
      "        \"dim\": 0\n",
      "      },\n",
      "      \"in\": \"out_neural_separate\",\n",
      "      \"out\": \"out_neural\"\n",
      "    }\n",
      "  ],\n",
      "  \"out\": [\n",
      "    \"out_neural\"\n",
      "  ],\n",
      "  \"comments\": {\n",
      "    \"conv_layers\": [\n",
      "      \"stack.layer_list.0.b_conv\",\n",
      "      \"stack.layer_list.1.b_conv\",\n",
      "      \"stack.layer_list.2.b_conv\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "moduledict.bl_stack.layer_list.0.b_conv.weight torch.Size([48, 1, 13, 13]) tensor(1.0089e-05) tensor(0.0099)\n",
      "moduledict.bl_stack.layer_list.1.b_conv.weight torch.Size([48, 48, 3, 3]) tensor(9.8976e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.2.b_conv.weight torch.Size([48, 48, 3, 3]) tensor(-4.3671e-05) tensor(0.0101)\n",
      "moduledict.bl_stack.bn_layer_list.0.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.0.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.1.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.1.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.2.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.2.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bn_input.weight torch.Size([1]) tensor(1.) tensor(nan)\n",
      "moduledict.bn_input.bias torch.Size([1]) tensor(0.) tensor(nan)\n",
      "moduledict.fc.weight_spatial torch.Size([3, 25, 25]) tensor(-5.5713e-05) tensor(0.0098)\n",
      "moduledict.fc.weight_feature torch.Size([3, 48]) tensor(0.0009) tensor(0.0099)\n",
      "moduledict.fc.bias torch.Size([3]) tensor(0.) tensor(0.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 3])\n",
      "torch.Size([1, 10, 3])\n"
     ]
    }
   ],
   "source": [
    "check_ff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fc'}\n",
      "{\n",
      "  \"module_dict\": {\n",
      "    \"bn_input\": {\n",
      "      \"name\": \"torch.nn.batchnorm2d\",\n",
      "      \"params\": {\n",
      "        \"num_features\": 1,\n",
      "        \"eps\": 0.001,\n",
      "        \"momentum\": 0.1,\n",
      "        \"affine\": true\n",
      "      },\n",
      "      \"init\": {}\n",
      "    },\n",
      "    \"bl_stack\": {\n",
      "      \"name\": \"rcnn_kriegeskorte.blstack\",\n",
      "      \"params\": {\n",
      "        \"n_timesteps\": 8,\n",
      "        \"channel_list\": [\n",
      "          1,\n",
      "          48,\n",
      "          48,\n",
      "          48\n",
      "        ],\n",
      "        \"ksize_list\": [\n",
      "          13,\n",
      "          3,\n",
      "          3\n",
      "        ],\n",
      "        \"pool_ksize\": 1,\n",
      "        \"act_fn\": \"softplus\"\n",
      "      },\n",
      "      \"init\": {\n",
      "        \"strategy\": \"normal\",\n",
      "        \"parameters\": {\n",
      "          \"std\": 0.01\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"accumulator\": {\n",
      "      \"name\": \"rcnn_kriegeskorte.accumulator\",\n",
      "      \"params\": {\n",
      "        \"mode\": \"instant\"\n",
      "      },\n",
      "      \"init\": null\n",
      "    },\n",
      "    \"pooling\": {\n",
      "      \"name\": \"torch.nn.maxpool2d\",\n",
      "      \"params\": {\n",
      "        \"kernel_size\": 1,\n",
      "        \"ceil_mode\": true\n",
      "      },\n",
      "      \"init\": null\n",
      "    },\n",
      "    \"fc\": {\n",
      "      \"name\": \"maskcnn.factoredfc\",\n",
      "      \"params\": {\n",
      "        \"in_channels\": 48,\n",
      "        \"map_size\": [\n",
      "          50,\n",
      "          50\n",
      "        ],\n",
      "        \"out_features\": 3,\n",
      "        \"bias\": true,\n",
      "        \"weight_feature_constraint\": null,\n",
      "        \"weight_spatial_constraint\": null\n",
      "      },\n",
      "      \"init\": {\n",
      "        \"strategy\": \"normal\",\n",
      "        \"parameters\": {\n",
      "          \"std\": 0.01\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"final_act\": {\n",
      "      \"name\": \"torch.nn.softplus\",\n",
      "      \"params\": {},\n",
      "      \"init\": null\n",
      "    }\n",
      "  },\n",
      "  \"op_list\": [\n",
      "    {\n",
      "      \"name\": \"sequential\",\n",
      "      \"args\": [\n",
      "        [\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"bn_input\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"bl_stack\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"accumulator\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      ],\n",
      "      \"kwargs\": {},\n",
      "      \"in\": \"input0\",\n",
      "      \"out\": \"feature_map\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"sequential\",\n",
      "      \"args\": [\n",
      "        [\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"fc\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          }\n",
      "        ]\n",
      "      ],\n",
      "      \"kwargs\": {},\n",
      "      \"in\": \"feature_map\",\n",
      "      \"out\": \"out_neural_separate\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"stack\",\n",
      "      \"args\": [],\n",
      "      \"kwargs\": {\n",
      "        \"dim\": 0\n",
      "      },\n",
      "      \"in\": \"out_neural_separate\",\n",
      "      \"out\": \"out_neural\"\n",
      "    }\n",
      "  ],\n",
      "  \"out\": [\n",
      "    \"out_neural\"\n",
      "  ],\n",
      "  \"comments\": {\n",
      "    \"conv_layers\": [\n",
      "      \"stack.layer_list.0.b_conv\",\n",
      "      \"stack.layer_list.1.b_conv\",\n",
      "      \"stack.layer_list.2.b_conv\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "moduledict.bl_stack.layer_list.0.b_conv.weight torch.Size([48, 1, 13, 13]) tensor(1.4950e-05) tensor(0.0101)\n",
      "moduledict.bl_stack.layer_list.0.l_conv.weight torch.Size([48, 48, 13, 13]) tensor(-8.2972e-06) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.1.b_conv.weight torch.Size([48, 48, 3, 3]) tensor(5.7371e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.1.l_conv.weight torch.Size([48, 48, 3, 3]) tensor(-3.5611e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.2.b_conv.weight torch.Size([48, 48, 3, 3]) tensor(1.1117e-05) tensor(0.0099)\n",
      "moduledict.bl_stack.layer_list.2.l_conv.weight torch.Size([48, 48, 3, 3]) tensor(4.7878e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.bn_layer_list.0.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.0.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.1.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.1.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.2.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.2.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.3.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.3.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.4.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.4.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.5.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.5.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.6.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.6.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.7.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.7.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.8.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.8.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.9.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.9.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.10.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.10.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.11.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.11.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.12.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.12.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.13.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.13.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.14.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.14.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.15.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.15.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.16.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.16.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.17.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.17.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.18.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.18.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.19.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.19.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.20.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.20.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.21.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.21.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.22.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.22.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.23.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.23.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bn_input.weight torch.Size([1]) tensor(1.) tensor(nan)\n",
      "moduledict.bn_input.bias torch.Size([1]) tensor(0.) tensor(nan)\n",
      "moduledict.fc.weight_spatial torch.Size([3, 50, 50]) tensor(-5.7668e-05) tensor(0.0100)\n",
      "moduledict.fc.weight_feature torch.Size([3, 48]) tensor(-0.0013) tensor(0.0103)\n",
      "moduledict.fc.bias torch.Size([3]) tensor(0.) tensor(0.)\n",
      "{'fc'}\n",
      "{\n",
      "  \"module_dict\": {\n",
      "    \"bn_input\": {\n",
      "      \"name\": \"torch.nn.batchnorm2d\",\n",
      "      \"params\": {\n",
      "        \"num_features\": 1,\n",
      "        \"eps\": 0.001,\n",
      "        \"momentum\": 0.1,\n",
      "        \"affine\": true\n",
      "      },\n",
      "      \"init\": {}\n",
      "    },\n",
      "    \"bl_stack\": {\n",
      "      \"name\": \"rcnn_kriegeskorte.blstack\",\n",
      "      \"params\": {\n",
      "        \"n_timesteps\": 8,\n",
      "        \"channel_list\": [\n",
      "          1,\n",
      "          48,\n",
      "          48,\n",
      "          48\n",
      "        ],\n",
      "        \"ksize_list\": [\n",
      "          13,\n",
      "          3,\n",
      "          3\n",
      "        ],\n",
      "        \"pool_ksize\": 1,\n",
      "        \"act_fn\": \"softplus\"\n",
      "      },\n",
      "      \"init\": {\n",
      "        \"strategy\": \"normal\",\n",
      "        \"parameters\": {\n",
      "          \"std\": 0.01\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"accumulator\": {\n",
      "      \"name\": \"rcnn_kriegeskorte.accumulator\",\n",
      "      \"params\": {\n",
      "        \"mode\": \"cummean\"\n",
      "      },\n",
      "      \"init\": null\n",
      "    },\n",
      "    \"pooling\": {\n",
      "      \"name\": \"torch.nn.maxpool2d\",\n",
      "      \"params\": {\n",
      "        \"kernel_size\": 1,\n",
      "        \"ceil_mode\": true\n",
      "      },\n",
      "      \"init\": null\n",
      "    },\n",
      "    \"fc\": {\n",
      "      \"name\": \"maskcnn.factoredfc\",\n",
      "      \"params\": {\n",
      "        \"in_channels\": 48,\n",
      "        \"map_size\": [\n",
      "          50,\n",
      "          50\n",
      "        ],\n",
      "        \"out_features\": 3,\n",
      "        \"bias\": true,\n",
      "        \"weight_feature_constraint\": null,\n",
      "        \"weight_spatial_constraint\": null\n",
      "      },\n",
      "      \"init\": {\n",
      "        \"strategy\": \"normal\",\n",
      "        \"parameters\": {\n",
      "          \"std\": 0.01\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"final_act\": {\n",
      "      \"name\": \"torch.nn.softplus\",\n",
      "      \"params\": {},\n",
      "      \"init\": null\n",
      "    }\n",
      "  },\n",
      "  \"op_list\": [\n",
      "    {\n",
      "      \"name\": \"sequential\",\n",
      "      \"args\": [\n",
      "        [\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"bn_input\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"bl_stack\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"accumulator\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      ],\n",
      "      \"kwargs\": {},\n",
      "      \"in\": \"input0\",\n",
      "      \"out\": \"feature_map\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"sequential\",\n",
      "      \"args\": [\n",
      "        [\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"fc\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          }\n",
      "        ]\n",
      "      ],\n",
      "      \"kwargs\": {},\n",
      "      \"in\": \"feature_map\",\n",
      "      \"out\": \"out_neural_separate\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"stack\",\n",
      "      \"args\": [],\n",
      "      \"kwargs\": {\n",
      "        \"dim\": 0\n",
      "      },\n",
      "      \"in\": \"out_neural_separate\",\n",
      "      \"out\": \"out_neural\"\n",
      "    }\n",
      "  ],\n",
      "  \"out\": [\n",
      "    \"out_neural\"\n",
      "  ],\n",
      "  \"comments\": {\n",
      "    \"conv_layers\": [\n",
      "      \"stack.layer_list.0.b_conv\",\n",
      "      \"stack.layer_list.1.b_conv\",\n",
      "      \"stack.layer_list.2.b_conv\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "moduledict.bl_stack.layer_list.0.b_conv.weight torch.Size([48, 1, 13, 13]) tensor(1.4950e-05) tensor(0.0101)\n",
      "moduledict.bl_stack.layer_list.0.l_conv.weight torch.Size([48, 48, 13, 13]) tensor(-8.2972e-06) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.1.b_conv.weight torch.Size([48, 48, 3, 3]) tensor(5.7371e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.1.l_conv.weight torch.Size([48, 48, 3, 3]) tensor(-3.5611e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.2.b_conv.weight torch.Size([48, 48, 3, 3]) tensor(1.1117e-05) tensor(0.0099)\n",
      "moduledict.bl_stack.layer_list.2.l_conv.weight torch.Size([48, 48, 3, 3]) tensor(4.7878e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.bn_layer_list.0.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.0.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.1.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.1.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.2.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.2.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.3.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.3.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.4.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.4.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.5.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.5.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.6.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.6.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.7.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.7.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.8.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.8.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.9.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.9.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.10.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.10.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.11.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.11.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.12.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.12.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.13.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.13.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.14.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.14.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.15.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.15.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.16.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.16.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.17.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.17.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.18.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.18.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.19.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.19.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.20.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.20.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.21.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.21.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.22.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.22.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.23.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.23.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bn_input.weight torch.Size([1]) tensor(1.) tensor(nan)\n",
      "moduledict.bn_input.bias torch.Size([1]) tensor(0.) tensor(nan)\n",
      "moduledict.fc.weight_spatial torch.Size([3, 50, 50]) tensor(-5.7668e-05) tensor(0.0100)\n",
      "moduledict.fc.weight_feature torch.Size([3, 48]) tensor(-0.0013) tensor(0.0103)\n",
      "moduledict.fc.bias torch.Size([3]) tensor(0.) tensor(0.)\n",
      "torch.Size([8, 10, 3])\n",
      "torch.Size([8, 10, 3])\n",
      "0.014933402 0.040460978\n",
      "0.014933402 0.040460978\n",
      "0.013559388 0.04107457\n",
      "0.013559388 0.04107457\n",
      "0.013146769 0.041380286\n",
      "0.01314677 0.04138029\n",
      "0.0129326815 0.04153129\n",
      "0.0129326815 0.041531295\n",
      "0.012805243 0.04162415\n",
      "0.012805242 0.041624155\n",
      "0.012719977 0.04168675\n",
      "0.012719978 0.04168675\n",
      "0.012658913 0.041731376\n",
      "0.012658912 0.041731384\n",
      "0.0126131 0.041764945\n",
      "0.012613096 0.041764945\n"
     ]
    }
   ],
   "source": [
    "check_instant_vs_cummean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pooling', 'final_act', 'bn_output', 'fc'}\n",
      "{\n",
      "  \"module_dict\": {\n",
      "    \"bn_input\": {\n",
      "      \"name\": \"torch.nn.batchnorm2d\",\n",
      "      \"params\": {\n",
      "        \"num_features\": 1,\n",
      "        \"eps\": 0.001,\n",
      "        \"momentum\": 0.1,\n",
      "        \"affine\": true\n",
      "      },\n",
      "      \"init\": {}\n",
      "    },\n",
      "    \"bl_stack\": {\n",
      "      \"name\": \"rcnn_kriegeskorte.blstack\",\n",
      "      \"params\": {\n",
      "        \"n_timesteps\": 8,\n",
      "        \"channel_list\": [\n",
      "          1,\n",
      "          48,\n",
      "          48,\n",
      "          48\n",
      "        ],\n",
      "        \"ksize_list\": [\n",
      "          13,\n",
      "          3,\n",
      "          3\n",
      "        ],\n",
      "        \"pool_ksize\": 1,\n",
      "        \"act_fn\": \"softplus\"\n",
      "      },\n",
      "      \"init\": {\n",
      "        \"strategy\": \"normal\",\n",
      "        \"parameters\": {\n",
      "          \"std\": 0.01\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"accumulator\": {\n",
      "      \"name\": \"rcnn_kriegeskorte.accumulator\",\n",
      "      \"params\": {\n",
      "        \"mode\": \"cummean\"\n",
      "      },\n",
      "      \"init\": null\n",
      "    },\n",
      "    \"pooling\": {\n",
      "      \"name\": \"torch.nn.maxpool2d\",\n",
      "      \"params\": {\n",
      "        \"kernel_size\": 2,\n",
      "        \"ceil_mode\": true\n",
      "      },\n",
      "      \"init\": null\n",
      "    },\n",
      "    \"fc\": {\n",
      "      \"name\": \"maskcnn.factoredfc\",\n",
      "      \"params\": {\n",
      "        \"in_channels\": 48,\n",
      "        \"map_size\": [\n",
      "          25,\n",
      "          25\n",
      "        ],\n",
      "        \"out_features\": 3,\n",
      "        \"bias\": true,\n",
      "        \"weight_feature_constraint\": null,\n",
      "        \"weight_spatial_constraint\": null\n",
      "      },\n",
      "      \"init\": {\n",
      "        \"strategy\": \"normal\",\n",
      "        \"parameters\": {\n",
      "          \"std\": 0.01\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"final_act\": {\n",
      "      \"name\": \"torch.nn.softplus\",\n",
      "      \"params\": {},\n",
      "      \"init\": null\n",
      "    }\n",
      "  },\n",
      "  \"op_list\": [\n",
      "    {\n",
      "      \"name\": \"sequential\",\n",
      "      \"args\": [\n",
      "        [\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"bn_input\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"bl_stack\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"accumulator\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      ],\n",
      "      \"kwargs\": {},\n",
      "      \"in\": \"input0\",\n",
      "      \"out\": \"feature_map\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"sequential\",\n",
      "      \"args\": [\n",
      "        [\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"pooling\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"fc\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"final_act\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          }\n",
      "        ]\n",
      "      ],\n",
      "      \"kwargs\": {},\n",
      "      \"in\": \"feature_map\",\n",
      "      \"out\": \"out_neural_separate\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"stack\",\n",
      "      \"args\": [],\n",
      "      \"kwargs\": {\n",
      "        \"dim\": 0\n",
      "      },\n",
      "      \"in\": \"out_neural_separate\",\n",
      "      \"out\": \"out_neural\"\n",
      "    }\n",
      "  ],\n",
      "  \"out\": [\n",
      "    \"out_neural\"\n",
      "  ],\n",
      "  \"comments\": {\n",
      "    \"conv_layers\": [\n",
      "      \"stack.layer_list.0.b_conv\",\n",
      "      \"stack.layer_list.1.b_conv\",\n",
      "      \"stack.layer_list.2.b_conv\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "moduledict.bl_stack.layer_list.0.b_conv.weight torch.Size([48, 1, 13, 13]) tensor(1.4950e-05) tensor(0.0101)\n",
      "moduledict.bl_stack.layer_list.0.l_conv.weight torch.Size([48, 48, 13, 13]) tensor(-8.2972e-06) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.1.b_conv.weight torch.Size([48, 48, 3, 3]) tensor(5.7371e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.1.l_conv.weight torch.Size([48, 48, 3, 3]) tensor(-3.5611e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.2.b_conv.weight torch.Size([48, 48, 3, 3]) tensor(1.1117e-05) tensor(0.0099)\n",
      "moduledict.bl_stack.layer_list.2.l_conv.weight torch.Size([48, 48, 3, 3]) tensor(4.7878e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.bn_layer_list.0.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.0.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.1.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.1.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.2.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.2.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.3.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.3.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.4.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.4.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.5.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.5.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.6.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.6.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.7.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.7.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.8.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.8.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.9.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.9.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.10.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.10.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.11.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.11.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.12.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.12.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.13.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.13.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.14.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.14.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.15.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.15.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.16.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.16.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.17.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.17.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.18.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.18.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.19.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.19.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.20.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.20.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.21.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.21.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.22.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.22.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.23.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.23.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bn_input.weight torch.Size([1]) tensor(1.) tensor(nan)\n",
      "moduledict.bn_input.bias torch.Size([1]) tensor(0.) tensor(nan)\n",
      "moduledict.fc.weight_spatial torch.Size([3, 25, 25]) tensor(3.6120e-05) tensor(0.0103)\n",
      "moduledict.fc.weight_feature torch.Size([3, 48]) tensor(0.0007) tensor(0.0096)\n",
      "moduledict.fc.bias torch.Size([3]) tensor(0.) tensor(0.)\n",
      "{'pooling', 'final_act', 'bn_output', 'fc'}\n",
      "['out_neural_separate']\n",
      "{\n",
      "  \"module_dict\": {\n",
      "    \"bn_input\": {\n",
      "      \"name\": \"torch.nn.batchnorm2d\",\n",
      "      \"params\": {\n",
      "        \"num_features\": 1,\n",
      "        \"eps\": 0.001,\n",
      "        \"momentum\": 0.1,\n",
      "        \"affine\": true\n",
      "      },\n",
      "      \"init\": {}\n",
      "    },\n",
      "    \"bl_stack\": {\n",
      "      \"name\": \"rcnn_kriegeskorte.blstack\",\n",
      "      \"params\": {\n",
      "        \"n_timesteps\": 8,\n",
      "        \"channel_list\": [\n",
      "          1,\n",
      "          48,\n",
      "          48,\n",
      "          48\n",
      "        ],\n",
      "        \"ksize_list\": [\n",
      "          13,\n",
      "          3,\n",
      "          3\n",
      "        ],\n",
      "        \"pool_ksize\": 1,\n",
      "        \"act_fn\": \"softplus\"\n",
      "      },\n",
      "      \"init\": {\n",
      "        \"strategy\": \"normal\",\n",
      "        \"parameters\": {\n",
      "          \"std\": 0.01\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"accumulator\": {\n",
      "      \"name\": \"rcnn_kriegeskorte.accumulator\",\n",
      "      \"params\": {\n",
      "        \"mode\": \"cummean\"\n",
      "      },\n",
      "      \"init\": null\n",
      "    },\n",
      "    \"pooling\": {\n",
      "      \"name\": \"torch.nn.maxpool2d\",\n",
      "      \"params\": {\n",
      "        \"kernel_size\": 2,\n",
      "        \"ceil_mode\": true\n",
      "      },\n",
      "      \"init\": null\n",
      "    },\n",
      "    \"fc\": {\n",
      "      \"name\": \"maskcnn.factoredfc\",\n",
      "      \"params\": {\n",
      "        \"in_channels\": 48,\n",
      "        \"map_size\": [\n",
      "          25,\n",
      "          25\n",
      "        ],\n",
      "        \"out_features\": 3,\n",
      "        \"bias\": true,\n",
      "        \"weight_feature_constraint\": null,\n",
      "        \"weight_spatial_constraint\": null\n",
      "      },\n",
      "      \"init\": {\n",
      "        \"strategy\": \"normal\",\n",
      "        \"parameters\": {\n",
      "          \"std\": 0.01\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"final_act\": {\n",
      "      \"name\": \"torch.nn.softplus\",\n",
      "      \"params\": {},\n",
      "      \"init\": null\n",
      "    }\n",
      "  },\n",
      "  \"op_list\": [\n",
      "    {\n",
      "      \"name\": \"sequential\",\n",
      "      \"args\": [\n",
      "        [\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"bn_input\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"bl_stack\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"accumulator\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      ],\n",
      "      \"kwargs\": {},\n",
      "      \"in\": \"input0\",\n",
      "      \"out\": \"feature_map\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"sequential\",\n",
      "      \"args\": [\n",
      "        [\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"pooling\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"fc\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"final_act\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          }\n",
      "        ]\n",
      "      ],\n",
      "      \"kwargs\": {},\n",
      "      \"in\": \"feature_map\",\n",
      "      \"out\": \"out_neural_separate\"\n",
      "    }\n",
      "  ],\n",
      "  \"out\": \"out_neural_separate\",\n",
      "  \"comments\": {\n",
      "    \"conv_layers\": [\n",
      "      \"stack.layer_list.0.b_conv\",\n",
      "      \"stack.layer_list.1.b_conv\",\n",
      "      \"stack.layer_list.2.b_conv\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "moduledict.bl_stack.layer_list.0.b_conv.weight torch.Size([48, 1, 13, 13]) tensor(1.4950e-05) tensor(0.0101)\n",
      "moduledict.bl_stack.layer_list.0.l_conv.weight torch.Size([48, 48, 13, 13]) tensor(-8.2972e-06) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.1.b_conv.weight torch.Size([48, 48, 3, 3]) tensor(5.7371e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.1.l_conv.weight torch.Size([48, 48, 3, 3]) tensor(-3.5611e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.2.b_conv.weight torch.Size([48, 48, 3, 3]) tensor(1.1117e-05) tensor(0.0099)\n",
      "moduledict.bl_stack.layer_list.2.l_conv.weight torch.Size([48, 48, 3, 3]) tensor(4.7878e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.bn_layer_list.0.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.0.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.1.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.1.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.2.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.2.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.3.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.3.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.4.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.4.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.5.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.5.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.6.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.6.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.7.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.7.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.8.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.8.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.9.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.9.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.10.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.10.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.11.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.11.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.12.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.12.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.13.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.13.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.14.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.14.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.15.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.15.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.16.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.16.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.17.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.17.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.18.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.18.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.19.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.19.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.20.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.20.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.21.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.21.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.22.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.22.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.23.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.23.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bn_input.weight torch.Size([1]) tensor(1.) tensor(nan)\n",
      "moduledict.bn_input.bias torch.Size([1]) tensor(0.) tensor(nan)\n",
      "moduledict.fc.weight_spatial torch.Size([3, 25, 25]) tensor(3.6120e-05) tensor(0.0103)\n",
      "moduledict.fc.weight_feature torch.Size([3, 48]) tensor(0.0007) tensor(0.0096)\n",
      "moduledict.fc.bias torch.Size([3]) tensor(0.) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "check_stack_vs_no_stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
