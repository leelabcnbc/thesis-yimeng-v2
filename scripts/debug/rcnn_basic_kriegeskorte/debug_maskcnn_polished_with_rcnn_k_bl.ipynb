{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import tensor, no_grad, Tensor\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from thesis_v2.models.maskcnn_polished_with_rcnn_k_bl.builder import (\n",
    "    gen_maskcnn_polished_with_rcnn_k_bl, load_modules\n",
    ")\n",
    "\n",
    "load_modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random_img = np.random.random_sample((10, 50, 50, 1))*2 - 1\n",
    "random_img = random_img.astype(np.float32)\n",
    "random_img = random_img.transpose((0,3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torchnetjson.builder import build_net\n",
    "\n",
    "def make_model(\n",
    "    *,\n",
    "    n_timesteps,\n",
    "    acc_mode,\n",
    "    pooling_ksize,\n",
    "    debug_args=None,\n",
    "):\n",
    "    model_json = gen_maskcnn_polished_with_rcnn_k_bl(\n",
    "        (50, 50), 3,\n",
    "        n_timesteps=n_timesteps,\n",
    "        acc_mode=acc_mode,\n",
    "        pooling_ksize=pooling_ksize,\n",
    "        debug_args=debug_args,\n",
    "        out_channel=48,\n",
    "        kernel_size_l1=13,\n",
    "        kernel_size_l23=3,\n",
    "        factored_constraint=None,\n",
    "        act_fn='softplus',\n",
    "        pooling_type='max',\n",
    "        num_layer=3,\n",
    "        blstack_pool_ksize=1,\n",
    "        blstack_pool_type=None,\n",
    "        bn_after_fc=False,\n",
    "    )\n",
    "    print(json.dumps(model_json, indent=2))\n",
    "    torch.manual_seed(0)\n",
    "    model = build_net(model_json)\n",
    "    print(model)\n",
    "    with no_grad():\n",
    "        for x, y in model.named_parameters():\n",
    "            print(x, y.size(), y.mean(), y.std())\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import max_pool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.backends import cudnn\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# let's put some test data.\n",
    "def eval_model(model_to_eval, check=True, model_args=None):\n",
    "    model_to_eval.cuda().eval()\n",
    "\n",
    "    with no_grad():\n",
    "        out_this = model_to_eval(tensor(random_img).cuda())\n",
    "        if check:\n",
    "            assert type(out_this) is tuple and len(out_this) == 1\n",
    "    \n",
    "    # let's do forward manually to make sure.\n",
    "    assert model_args is not None\n",
    "    if model_args is not None:\n",
    "        n_timesteps = model_to_eval.get_module('bl_stack').n_timesteps\n",
    "        with no_grad():\n",
    "            # first, do the conv part.\n",
    "            x = tensor(random_img).cuda()\n",
    "            x = model_to_eval.get_module('bn_input')(x)\n",
    "            x = model_to_eval.get_module('bl_stack')(x)\n",
    "            # accumulator\n",
    "            if model_args['acc_mode'] == 'instant':\n",
    "                pass\n",
    "            elif model_args['acc_mode'] == 'cummean':\n",
    "                x = tuple(torch.mean(torch.stack(x[:i + 1]), 0) for i in range(len(x)))\n",
    "            else:\n",
    "                raise ValueError\n",
    "            # second, the sequential part.\n",
    "            only_fc = model_args['debug_args'].get('only_fc', False)\n",
    "            if only_fc:\n",
    "                assert model_args['pooling_ksize'] == 1\n",
    "                x = tuple(model_to_eval.get_module('fc')(z) for z in x)\n",
    "            else:\n",
    "                # do pooling.\n",
    "                x = tuple(max_pool2d(\n",
    "                    z, kernel_size=model_args['pooling_ksize'],\n",
    "                    ceil_mode=True) for z in x)\n",
    "                x = tuple(model_to_eval.get_module('fc')(z) for z in x)\n",
    "                if model_args.get('bn_output', False):\n",
    "                    x = tuple(model_to_eval.get_module('bn_output')(z) for z in x)\n",
    "                x = tuple(model_to_eval.get_module('final_act')(z) for z in x)\n",
    "            \n",
    "            if model_args['debug_args'].get('stack', True):\n",
    "                x = (torch.stack(x, 0),)\n",
    "            \n",
    "            \n",
    "        assert type(out_this) is type(x)\n",
    "        if type(out_this) is Tensor:\n",
    "            raise RuntimeError\n",
    "        else:\n",
    "            assert type(out_this) is tuple\n",
    "            print(len(out_this), len(x))\n",
    "            print(x[0].size())\n",
    "            assert len(out_this) == len(x)\n",
    "            for k1, k2 in zip(out_this, x):\n",
    "                assert torch.equal(k1, k2)\n",
    "    \n",
    "    if check:\n",
    "        print(out_this[0].size())\n",
    "        return out_this[0].detach().cpu().numpy()\n",
    "    else:\n",
    "        return out_this\n",
    "\n",
    "\n",
    "def check_ff():\n",
    "    model_a = make_model(\n",
    "        n_timesteps=1,\n",
    "        acc_mode='instant',\n",
    "        pooling_ksize=2,\n",
    "    )\n",
    "    model_b = make_model(\n",
    "        n_timesteps=1,\n",
    "        acc_mode='cummean',\n",
    "        pooling_ksize=2,\n",
    "    )\n",
    "    out_a = eval_model(model_a,\n",
    "                       model_args={\n",
    "                           'acc_mode': 'instant',\n",
    "                           'pooling_ksize': 2,\n",
    "                           'debug_args': {},\n",
    "                       }\n",
    "                      )\n",
    "    out_b = eval_model(model_b,\n",
    "                       model_args={\n",
    "                           'acc_mode': 'cummean',\n",
    "                           'pooling_ksize': 2,\n",
    "                           'debug_args': {},\n",
    "                       }\n",
    "                      )\n",
    "    \n",
    "    assert np.array_equal(out_a, out_b)\n",
    "\n",
    "    \n",
    "def check_instant_vs_cummean():\n",
    "    model_a = make_model(\n",
    "        n_timesteps=8,\n",
    "        acc_mode='instant',\n",
    "        pooling_ksize=1,\n",
    "        debug_args={'only_fc': True}\n",
    "    )\n",
    "    model_b = make_model(\n",
    "        n_timesteps=8,\n",
    "        acc_mode='cummean',\n",
    "        pooling_ksize=1,\n",
    "        debug_args={'only_fc': True}\n",
    "    )\n",
    "    out_a = eval_model(model_a,\n",
    "                       model_args={\n",
    "                           'acc_mode': 'instant',\n",
    "                           'debug_args': {'only_fc': True},\n",
    "                           'pooling_ksize': 1,\n",
    "                       }\n",
    "                      )\n",
    "    out_b = eval_model(model_b,\n",
    "                       model_args={\n",
    "                           'acc_mode': 'cummean',\n",
    "                           'debug_args': {'only_fc': True},\n",
    "                           'pooling_ksize': 1,\n",
    "                       }\n",
    "                      )\n",
    "    \n",
    "    assert out_a.shape == out_b.shape == (8, 10, 3)\n",
    "    \n",
    "    for idx in range(8):\n",
    "        instant_out = np.mean(out_a[:idx+1], axis=0)\n",
    "        cummean_out = out_b[idx]\n",
    "        assert instant_out.shape == cummean_out.shape == (10,3)\n",
    "        print(instant_out.mean(), instant_out.std())\n",
    "        print(cummean_out.mean(), cummean_out.std())\n",
    "        assert np.allclose(instant_out, cummean_out, atol=1e-5)\n",
    "\n",
    "def check_stack_vs_no_stack():\n",
    "    model_a = make_model(\n",
    "        n_timesteps=8,\n",
    "        acc_mode='cummean',\n",
    "        pooling_ksize=2,\n",
    "    )\n",
    "    model_b = make_model(\n",
    "        n_timesteps=8,\n",
    "        acc_mode='cummean',\n",
    "        pooling_ksize=2,\n",
    "        debug_args={'stack': False}\n",
    "    )\n",
    "    \n",
    "    out_a = eval_model(model_a, check=False,\n",
    "                       model_args={\n",
    "                           'acc_mode': 'cummean',\n",
    "                           'debug_args': {},\n",
    "                           'pooling_ksize': 2\n",
    "                       }\n",
    "                      )\n",
    "    out_b = eval_model(model_b, check=False,\n",
    "                       model_args={\n",
    "                           'acc_mode': 'cummean',\n",
    "                           'debug_args': {'stack': False},\n",
    "                           'pooling_ksize': 2\n",
    "                       }\n",
    "                      )\n",
    "    out_a = out_a[0].detach().cpu().numpy()\n",
    "    out_b = [x.detach().cpu().numpy() for x in out_b]\n",
    "    assert out_a.shape == (8, 10, 3)\n",
    "    assert np.array_equal(out_a, np.asarray(out_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'final_act', 'fc', 'pooling', 'bn_output'}\n",
      "{\n",
      "  \"module_dict\": {\n",
      "    \"bn_input\": {\n",
      "      \"name\": \"torch.nn.batchnorm2d\",\n",
      "      \"params\": {\n",
      "        \"num_features\": 1,\n",
      "        \"eps\": 0.001,\n",
      "        \"momentum\": 0.1,\n",
      "        \"affine\": true\n",
      "      },\n",
      "      \"init\": {}\n",
      "    },\n",
      "    \"bl_stack\": {\n",
      "      \"name\": \"rcnn_kriegeskorte.blstack\",\n",
      "      \"params\": {\n",
      "        \"n_timesteps\": 1,\n",
      "        \"channel_list\": [\n",
      "          1,\n",
      "          48,\n",
      "          48,\n",
      "          48\n",
      "        ],\n",
      "        \"ksize_list\": [\n",
      "          13,\n",
      "          3,\n",
      "          3\n",
      "        ],\n",
      "        \"pool_ksize\": 1,\n",
      "        \"pool_type\": null,\n",
      "        \"act_fn\": \"softplus\"\n",
      "      },\n",
      "      \"init\": {\n",
      "        \"strategy\": \"normal\",\n",
      "        \"parameters\": {\n",
      "          \"std\": 0.01\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"accumulator\": {\n",
      "      \"name\": \"rcnn_kriegeskorte.accumulator\",\n",
      "      \"params\": {\n",
      "        \"mode\": \"instant\"\n",
      "      },\n",
      "      \"init\": null\n",
      "    },\n",
      "    \"pooling\": {\n",
      "      \"name\": \"torch.nn.maxpool2d\",\n",
      "      \"params\": {\n",
      "        \"kernel_size\": 2,\n",
      "        \"ceil_mode\": true\n",
      "      },\n",
      "      \"init\": null\n",
      "    },\n",
      "    \"fc\": {\n",
      "      \"name\": \"maskcnn.factoredfc\",\n",
      "      \"params\": {\n",
      "        \"in_channels\": 48,\n",
      "        \"map_size\": [\n",
      "          25,\n",
      "          25\n",
      "        ],\n",
      "        \"out_features\": 3,\n",
      "        \"bias\": true,\n",
      "        \"weight_feature_constraint\": null,\n",
      "        \"weight_spatial_constraint\": null\n",
      "      },\n",
      "      \"init\": {\n",
      "        \"strategy\": \"normal\",\n",
      "        \"parameters\": {\n",
      "          \"std\": 0.01\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"final_act\": {\n",
      "      \"name\": \"torch.nn.softplus\",\n",
      "      \"params\": {},\n",
      "      \"init\": null\n",
      "    }\n",
      "  },\n",
      "  \"op_list\": [\n",
      "    {\n",
      "      \"name\": \"sequential\",\n",
      "      \"args\": [\n",
      "        [\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"bn_input\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"bl_stack\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"accumulator\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      ],\n",
      "      \"kwargs\": {},\n",
      "      \"in\": \"input0\",\n",
      "      \"out\": \"feature_map\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"sequential\",\n",
      "      \"args\": [\n",
      "        [\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"pooling\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"fc\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"final_act\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          }\n",
      "        ]\n",
      "      ],\n",
      "      \"kwargs\": {},\n",
      "      \"in\": \"feature_map\",\n",
      "      \"out\": \"out_neural_separate\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"stack\",\n",
      "      \"args\": [],\n",
      "      \"kwargs\": {\n",
      "        \"dim\": 0\n",
      "      },\n",
      "      \"in\": \"out_neural_separate\",\n",
      "      \"out\": \"out_neural\"\n",
      "    }\n",
      "  ],\n",
      "  \"out\": [\n",
      "    \"out_neural\"\n",
      "  ],\n",
      "  \"comments\": {\n",
      "    \"conv_layers\": [\n",
      "      \"bl_stack.layer_list.0.b_conv\",\n",
      "      \"bl_stack.layer_list.1.b_conv\",\n",
      "      \"bl_stack.layer_list.2.b_conv\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "JSONNet(\n",
      "  (moduledict): ModuleDict(\n",
      "    (accumulator): RecurrentAccumulator()\n",
      "    (bl_stack): BLConvLayerStack(\n",
      "      (layer_list): ModuleList(\n",
      "        (0): BLConvLayer(\n",
      "          (b_conv): Conv2d(1, 48, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), bias=False)\n",
      "        )\n",
      "        (1): BLConvLayer(\n",
      "          (b_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BLConvLayer(\n",
      "          (b_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bn_layer_list): ModuleList(\n",
      "        (0): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act_fn): Softplus(beta=1, threshold=20)\n",
      "      (pool): Identity()\n",
      "    )\n",
      "    (bn_input): BatchNorm2d(1, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc): FactoredLinear2D()\n",
      "    (final_act): Softplus(beta=1, threshold=20)\n",
      "    (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      ")\n",
      "moduledict.bl_stack.layer_list.0.b_conv.weight torch.Size([48, 1, 13, 13]) tensor(1.0089e-05) tensor(0.0099)\n",
      "moduledict.bl_stack.layer_list.1.b_conv.weight torch.Size([48, 48, 3, 3]) tensor(9.8976e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.2.b_conv.weight torch.Size([48, 48, 3, 3]) tensor(-4.3671e-05) tensor(0.0101)\n",
      "moduledict.bl_stack.bn_layer_list.0.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.0.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.1.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.1.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.2.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.2.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bn_input.weight torch.Size([1]) tensor(1.) tensor(nan)\n",
      "moduledict.bn_input.bias torch.Size([1]) tensor(0.) tensor(nan)\n",
      "moduledict.fc.weight_spatial torch.Size([3, 25, 25]) tensor(-5.5713e-05) tensor(0.0098)\n",
      "moduledict.fc.weight_feature torch.Size([3, 48]) tensor(0.0009) tensor(0.0099)\n",
      "moduledict.fc.bias torch.Size([3]) tensor(0.) tensor(0.)\n",
      "{'final_act', 'fc', 'pooling', 'bn_output'}\n",
      "{\n",
      "  \"module_dict\": {\n",
      "    \"bn_input\": {\n",
      "      \"name\": \"torch.nn.batchnorm2d\",\n",
      "      \"params\": {\n",
      "        \"num_features\": 1,\n",
      "        \"eps\": 0.001,\n",
      "        \"momentum\": 0.1,\n",
      "        \"affine\": true\n",
      "      },\n",
      "      \"init\": {}\n",
      "    },\n",
      "    \"bl_stack\": {\n",
      "      \"name\": \"rcnn_kriegeskorte.blstack\",\n",
      "      \"params\": {\n",
      "        \"n_timesteps\": 1,\n",
      "        \"channel_list\": [\n",
      "          1,\n",
      "          48,\n",
      "          48,\n",
      "          48\n",
      "        ],\n",
      "        \"ksize_list\": [\n",
      "          13,\n",
      "          3,\n",
      "          3\n",
      "        ],\n",
      "        \"pool_ksize\": 1,\n",
      "        \"pool_type\": null,\n",
      "        \"act_fn\": \"softplus\"\n",
      "      },\n",
      "      \"init\": {\n",
      "        \"strategy\": \"normal\",\n",
      "        \"parameters\": {\n",
      "          \"std\": 0.01\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"accumulator\": {\n",
      "      \"name\": \"rcnn_kriegeskorte.accumulator\",\n",
      "      \"params\": {\n",
      "        \"mode\": \"cummean\"\n",
      "      },\n",
      "      \"init\": null\n",
      "    },\n",
      "    \"pooling\": {\n",
      "      \"name\": \"torch.nn.maxpool2d\",\n",
      "      \"params\": {\n",
      "        \"kernel_size\": 2,\n",
      "        \"ceil_mode\": true\n",
      "      },\n",
      "      \"init\": null\n",
      "    },\n",
      "    \"fc\": {\n",
      "      \"name\": \"maskcnn.factoredfc\",\n",
      "      \"params\": {\n",
      "        \"in_channels\": 48,\n",
      "        \"map_size\": [\n",
      "          25,\n",
      "          25\n",
      "        ],\n",
      "        \"out_features\": 3,\n",
      "        \"bias\": true,\n",
      "        \"weight_feature_constraint\": null,\n",
      "        \"weight_spatial_constraint\": null\n",
      "      },\n",
      "      \"init\": {\n",
      "        \"strategy\": \"normal\",\n",
      "        \"parameters\": {\n",
      "          \"std\": 0.01\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"final_act\": {\n",
      "      \"name\": \"torch.nn.softplus\",\n",
      "      \"params\": {},\n",
      "      \"init\": null\n",
      "    }\n",
      "  },\n",
      "  \"op_list\": [\n",
      "    {\n",
      "      \"name\": \"sequential\",\n",
      "      \"args\": [\n",
      "        [\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"bn_input\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"bl_stack\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"accumulator\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      ],\n",
      "      \"kwargs\": {},\n",
      "      \"in\": \"input0\",\n",
      "      \"out\": \"feature_map\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"sequential\",\n",
      "      \"args\": [\n",
      "        [\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"pooling\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"fc\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"final_act\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          }\n",
      "        ]\n",
      "      ],\n",
      "      \"kwargs\": {},\n",
      "      \"in\": \"feature_map\",\n",
      "      \"out\": \"out_neural_separate\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"stack\",\n",
      "      \"args\": [],\n",
      "      \"kwargs\": {\n",
      "        \"dim\": 0\n",
      "      },\n",
      "      \"in\": \"out_neural_separate\",\n",
      "      \"out\": \"out_neural\"\n",
      "    }\n",
      "  ],\n",
      "  \"out\": [\n",
      "    \"out_neural\"\n",
      "  ],\n",
      "  \"comments\": {\n",
      "    \"conv_layers\": [\n",
      "      \"bl_stack.layer_list.0.b_conv\",\n",
      "      \"bl_stack.layer_list.1.b_conv\",\n",
      "      \"bl_stack.layer_list.2.b_conv\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "JSONNet(\n",
      "  (moduledict): ModuleDict(\n",
      "    (accumulator): RecurrentAccumulator()\n",
      "    (bl_stack): BLConvLayerStack(\n",
      "      (layer_list): ModuleList(\n",
      "        (0): BLConvLayer(\n",
      "          (b_conv): Conv2d(1, 48, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), bias=False)\n",
      "        )\n",
      "        (1): BLConvLayer(\n",
      "          (b_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BLConvLayer(\n",
      "          (b_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bn_layer_list): ModuleList(\n",
      "        (0): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act_fn): Softplus(beta=1, threshold=20)\n",
      "      (pool): Identity()\n",
      "    )\n",
      "    (bn_input): BatchNorm2d(1, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc): FactoredLinear2D()\n",
      "    (final_act): Softplus(beta=1, threshold=20)\n",
      "    (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      ")\n",
      "moduledict.bl_stack.layer_list.0.b_conv.weight torch.Size([48, 1, 13, 13]) tensor(1.0089e-05) tensor(0.0099)\n",
      "moduledict.bl_stack.layer_list.1.b_conv.weight torch.Size([48, 48, 3, 3]) tensor(9.8976e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.2.b_conv.weight torch.Size([48, 48, 3, 3]) tensor(-4.3671e-05) tensor(0.0101)\n",
      "moduledict.bl_stack.bn_layer_list.0.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.0.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.1.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.1.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.2.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.2.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bn_input.weight torch.Size([1]) tensor(1.) tensor(nan)\n",
      "moduledict.bn_input.bias torch.Size([1]) tensor(0.) tensor(nan)\n",
      "moduledict.fc.weight_spatial torch.Size([3, 25, 25]) tensor(-5.5713e-05) tensor(0.0098)\n",
      "moduledict.fc.weight_feature torch.Size([3, 48]) tensor(0.0009) tensor(0.0099)\n",
      "moduledict.fc.bias torch.Size([3]) tensor(0.) tensor(0.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "torch.Size([1, 10, 3])\n",
      "torch.Size([1, 10, 3])\n",
      "1 1\n",
      "torch.Size([1, 10, 3])\n",
      "torch.Size([1, 10, 3])\n"
     ]
    }
   ],
   "source": [
    "check_ff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fc'}\n",
      "{\n",
      "  \"module_dict\": {\n",
      "    \"bn_input\": {\n",
      "      \"name\": \"torch.nn.batchnorm2d\",\n",
      "      \"params\": {\n",
      "        \"num_features\": 1,\n",
      "        \"eps\": 0.001,\n",
      "        \"momentum\": 0.1,\n",
      "        \"affine\": true\n",
      "      },\n",
      "      \"init\": {}\n",
      "    },\n",
      "    \"bl_stack\": {\n",
      "      \"name\": \"rcnn_kriegeskorte.blstack\",\n",
      "      \"params\": {\n",
      "        \"n_timesteps\": 8,\n",
      "        \"channel_list\": [\n",
      "          1,\n",
      "          48,\n",
      "          48,\n",
      "          48\n",
      "        ],\n",
      "        \"ksize_list\": [\n",
      "          13,\n",
      "          3,\n",
      "          3\n",
      "        ],\n",
      "        \"pool_ksize\": 1,\n",
      "        \"pool_type\": null,\n",
      "        \"act_fn\": \"softplus\"\n",
      "      },\n",
      "      \"init\": {\n",
      "        \"strategy\": \"normal\",\n",
      "        \"parameters\": {\n",
      "          \"std\": 0.01\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"accumulator\": {\n",
      "      \"name\": \"rcnn_kriegeskorte.accumulator\",\n",
      "      \"params\": {\n",
      "        \"mode\": \"instant\"\n",
      "      },\n",
      "      \"init\": null\n",
      "    },\n",
      "    \"pooling\": {\n",
      "      \"name\": \"torch.nn.maxpool2d\",\n",
      "      \"params\": {\n",
      "        \"kernel_size\": 1,\n",
      "        \"ceil_mode\": true\n",
      "      },\n",
      "      \"init\": null\n",
      "    },\n",
      "    \"fc\": {\n",
      "      \"name\": \"maskcnn.factoredfc\",\n",
      "      \"params\": {\n",
      "        \"in_channels\": 48,\n",
      "        \"map_size\": [\n",
      "          50,\n",
      "          50\n",
      "        ],\n",
      "        \"out_features\": 3,\n",
      "        \"bias\": true,\n",
      "        \"weight_feature_constraint\": null,\n",
      "        \"weight_spatial_constraint\": null\n",
      "      },\n",
      "      \"init\": {\n",
      "        \"strategy\": \"normal\",\n",
      "        \"parameters\": {\n",
      "          \"std\": 0.01\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"final_act\": {\n",
      "      \"name\": \"torch.nn.softplus\",\n",
      "      \"params\": {},\n",
      "      \"init\": null\n",
      "    }\n",
      "  },\n",
      "  \"op_list\": [\n",
      "    {\n",
      "      \"name\": \"sequential\",\n",
      "      \"args\": [\n",
      "        [\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"bn_input\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"bl_stack\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"accumulator\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      ],\n",
      "      \"kwargs\": {},\n",
      "      \"in\": \"input0\",\n",
      "      \"out\": \"feature_map\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"sequential\",\n",
      "      \"args\": [\n",
      "        [\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"fc\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          }\n",
      "        ]\n",
      "      ],\n",
      "      \"kwargs\": {},\n",
      "      \"in\": \"feature_map\",\n",
      "      \"out\": \"out_neural_separate\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"stack\",\n",
      "      \"args\": [],\n",
      "      \"kwargs\": {\n",
      "        \"dim\": 0\n",
      "      },\n",
      "      \"in\": \"out_neural_separate\",\n",
      "      \"out\": \"out_neural\"\n",
      "    }\n",
      "  ],\n",
      "  \"out\": [\n",
      "    \"out_neural\"\n",
      "  ],\n",
      "  \"comments\": {\n",
      "    \"conv_layers\": [\n",
      "      \"bl_stack.layer_list.0.b_conv\",\n",
      "      \"bl_stack.layer_list.1.b_conv\",\n",
      "      \"bl_stack.layer_list.2.b_conv\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "JSONNet(\n",
      "  (moduledict): ModuleDict(\n",
      "    (accumulator): RecurrentAccumulator()\n",
      "    (bl_stack): BLConvLayerStack(\n",
      "      (layer_list): ModuleList(\n",
      "        (0): BLConvLayer(\n",
      "          (b_conv): Conv2d(1, 48, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), bias=False)\n",
      "          (l_conv): Conv2d(48, 48, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), bias=False)\n",
      "        )\n",
      "        (1): BLConvLayer(\n",
      "          (b_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (l_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BLConvLayer(\n",
      "          (b_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (l_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bn_layer_list): ModuleList(\n",
      "        (0): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (8): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (9): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (10): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (11): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (12): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (13): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (14): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (15): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (16): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (17): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (18): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (19): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (20): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (21): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (22): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (23): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act_fn): Softplus(beta=1, threshold=20)\n",
      "      (pool): Identity()\n",
      "    )\n",
      "    (bn_input): BatchNorm2d(1, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc): FactoredLinear2D()\n",
      "    (final_act): Softplus(beta=1, threshold=20)\n",
      "    (pooling): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      ")\n",
      "moduledict.bl_stack.layer_list.0.b_conv.weight torch.Size([48, 1, 13, 13]) tensor(1.4950e-05) tensor(0.0101)\n",
      "moduledict.bl_stack.layer_list.0.l_conv.weight torch.Size([48, 48, 13, 13]) tensor(-8.2972e-06) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.1.b_conv.weight torch.Size([48, 48, 3, 3]) tensor(5.7371e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.1.l_conv.weight torch.Size([48, 48, 3, 3]) tensor(-3.5611e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.2.b_conv.weight torch.Size([48, 48, 3, 3]) tensor(1.1117e-05) tensor(0.0099)\n",
      "moduledict.bl_stack.layer_list.2.l_conv.weight torch.Size([48, 48, 3, 3]) tensor(4.7878e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.bn_layer_list.0.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.0.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.1.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.1.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.2.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.2.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.3.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.3.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.4.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.4.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.5.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.5.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.6.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.6.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.7.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.7.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.8.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.8.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.9.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.9.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.10.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.10.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.11.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.11.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.12.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.12.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.13.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.13.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.14.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.14.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.15.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.15.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.16.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.16.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.17.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.17.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.18.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.18.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.19.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.19.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.20.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.20.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.21.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.21.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.22.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.22.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.23.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.23.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bn_input.weight torch.Size([1]) tensor(1.) tensor(nan)\n",
      "moduledict.bn_input.bias torch.Size([1]) tensor(0.) tensor(nan)\n",
      "moduledict.fc.weight_spatial torch.Size([3, 50, 50]) tensor(-5.7668e-05) tensor(0.0100)\n",
      "moduledict.fc.weight_feature torch.Size([3, 48]) tensor(-0.0013) tensor(0.0103)\n",
      "moduledict.fc.bias torch.Size([3]) tensor(0.) tensor(0.)\n",
      "{'fc'}\n",
      "{\n",
      "  \"module_dict\": {\n",
      "    \"bn_input\": {\n",
      "      \"name\": \"torch.nn.batchnorm2d\",\n",
      "      \"params\": {\n",
      "        \"num_features\": 1,\n",
      "        \"eps\": 0.001,\n",
      "        \"momentum\": 0.1,\n",
      "        \"affine\": true\n",
      "      },\n",
      "      \"init\": {}\n",
      "    },\n",
      "    \"bl_stack\": {\n",
      "      \"name\": \"rcnn_kriegeskorte.blstack\",\n",
      "      \"params\": {\n",
      "        \"n_timesteps\": 8,\n",
      "        \"channel_list\": [\n",
      "          1,\n",
      "          48,\n",
      "          48,\n",
      "          48\n",
      "        ],\n",
      "        \"ksize_list\": [\n",
      "          13,\n",
      "          3,\n",
      "          3\n",
      "        ],\n",
      "        \"pool_ksize\": 1,\n",
      "        \"pool_type\": null,\n",
      "        \"act_fn\": \"softplus\"\n",
      "      },\n",
      "      \"init\": {\n",
      "        \"strategy\": \"normal\",\n",
      "        \"parameters\": {\n",
      "          \"std\": 0.01\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"accumulator\": {\n",
      "      \"name\": \"rcnn_kriegeskorte.accumulator\",\n",
      "      \"params\": {\n",
      "        \"mode\": \"cummean\"\n",
      "      },\n",
      "      \"init\": null\n",
      "    },\n",
      "    \"pooling\": {\n",
      "      \"name\": \"torch.nn.maxpool2d\",\n",
      "      \"params\": {\n",
      "        \"kernel_size\": 1,\n",
      "        \"ceil_mode\": true\n",
      "      },\n",
      "      \"init\": null\n",
      "    },\n",
      "    \"fc\": {\n",
      "      \"name\": \"maskcnn.factoredfc\",\n",
      "      \"params\": {\n",
      "        \"in_channels\": 48,\n",
      "        \"map_size\": [\n",
      "          50,\n",
      "          50\n",
      "        ],\n",
      "        \"out_features\": 3,\n",
      "        \"bias\": true,\n",
      "        \"weight_feature_constraint\": null,\n",
      "        \"weight_spatial_constraint\": null\n",
      "      },\n",
      "      \"init\": {\n",
      "        \"strategy\": \"normal\",\n",
      "        \"parameters\": {\n",
      "          \"std\": 0.01\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"final_act\": {\n",
      "      \"name\": \"torch.nn.softplus\",\n",
      "      \"params\": {},\n",
      "      \"init\": null\n",
      "    }\n",
      "  },\n",
      "  \"op_list\": [\n",
      "    {\n",
      "      \"name\": \"sequential\",\n",
      "      \"args\": [\n",
      "        [\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"bn_input\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"bl_stack\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"accumulator\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      ],\n",
      "      \"kwargs\": {},\n",
      "      \"in\": \"input0\",\n",
      "      \"out\": \"feature_map\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"sequential\",\n",
      "      \"args\": [\n",
      "        [\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"fc\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          }\n",
      "        ]\n",
      "      ],\n",
      "      \"kwargs\": {},\n",
      "      \"in\": \"feature_map\",\n",
      "      \"out\": \"out_neural_separate\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"stack\",\n",
      "      \"args\": [],\n",
      "      \"kwargs\": {\n",
      "        \"dim\": 0\n",
      "      },\n",
      "      \"in\": \"out_neural_separate\",\n",
      "      \"out\": \"out_neural\"\n",
      "    }\n",
      "  ],\n",
      "  \"out\": [\n",
      "    \"out_neural\"\n",
      "  ],\n",
      "  \"comments\": {\n",
      "    \"conv_layers\": [\n",
      "      \"bl_stack.layer_list.0.b_conv\",\n",
      "      \"bl_stack.layer_list.1.b_conv\",\n",
      "      \"bl_stack.layer_list.2.b_conv\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "JSONNet(\n",
      "  (moduledict): ModuleDict(\n",
      "    (accumulator): RecurrentAccumulator()\n",
      "    (bl_stack): BLConvLayerStack(\n",
      "      (layer_list): ModuleList(\n",
      "        (0): BLConvLayer(\n",
      "          (b_conv): Conv2d(1, 48, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), bias=False)\n",
      "          (l_conv): Conv2d(48, 48, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), bias=False)\n",
      "        )\n",
      "        (1): BLConvLayer(\n",
      "          (b_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (l_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BLConvLayer(\n",
      "          (b_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (l_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bn_layer_list): ModuleList(\n",
      "        (0): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (8): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (9): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (10): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (11): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (12): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (13): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (14): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (15): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (16): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (17): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (18): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (19): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (20): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (21): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (22): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (23): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act_fn): Softplus(beta=1, threshold=20)\n",
      "      (pool): Identity()\n",
      "    )\n",
      "    (bn_input): BatchNorm2d(1, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc): FactoredLinear2D()\n",
      "    (final_act): Softplus(beta=1, threshold=20)\n",
      "    (pooling): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      ")\n",
      "moduledict.bl_stack.layer_list.0.b_conv.weight torch.Size([48, 1, 13, 13]) tensor(1.4950e-05) tensor(0.0101)\n",
      "moduledict.bl_stack.layer_list.0.l_conv.weight torch.Size([48, 48, 13, 13]) tensor(-8.2972e-06) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.1.b_conv.weight torch.Size([48, 48, 3, 3]) tensor(5.7371e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.1.l_conv.weight torch.Size([48, 48, 3, 3]) tensor(-3.5611e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.2.b_conv.weight torch.Size([48, 48, 3, 3]) tensor(1.1117e-05) tensor(0.0099)\n",
      "moduledict.bl_stack.layer_list.2.l_conv.weight torch.Size([48, 48, 3, 3]) tensor(4.7878e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.bn_layer_list.0.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.0.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.1.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.1.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.2.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.2.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.3.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.3.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.4.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.4.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.5.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.5.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.6.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.6.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.7.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.7.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.8.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.8.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.9.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.9.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.10.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.10.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.11.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.11.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.12.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.12.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.13.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.13.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.14.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.14.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.15.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.15.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.16.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.16.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.17.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.17.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.18.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.18.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.19.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.19.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.20.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.20.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.21.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.21.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.22.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.22.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.23.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.23.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bn_input.weight torch.Size([1]) tensor(1.) tensor(nan)\n",
      "moduledict.bn_input.bias torch.Size([1]) tensor(0.) tensor(nan)\n",
      "moduledict.fc.weight_spatial torch.Size([3, 50, 50]) tensor(-5.7668e-05) tensor(0.0100)\n",
      "moduledict.fc.weight_feature torch.Size([3, 48]) tensor(-0.0013) tensor(0.0103)\n",
      "moduledict.fc.bias torch.Size([3]) tensor(0.) tensor(0.)\n",
      "1 1\n",
      "torch.Size([8, 10, 3])\n",
      "torch.Size([8, 10, 3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "torch.Size([8, 10, 3])\n",
      "torch.Size([8, 10, 3])\n",
      "0.014933402 0.040460978\n",
      "0.014933402 0.040460978\n",
      "0.013559388 0.04107457\n",
      "0.013559388 0.04107457\n",
      "0.013146769 0.041380286\n",
      "0.01314677 0.04138029\n",
      "0.0129326815 0.04153129\n",
      "0.0129326815 0.041531295\n",
      "0.012805243 0.04162415\n",
      "0.012805242 0.041624155\n",
      "0.012719977 0.04168675\n",
      "0.012719978 0.04168675\n",
      "0.012658913 0.041731376\n",
      "0.012658912 0.041731384\n",
      "0.0126131 0.041764945\n",
      "0.012613096 0.041764945\n"
     ]
    }
   ],
   "source": [
    "check_instant_vs_cummean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'final_act', 'fc', 'pooling', 'bn_output'}\n",
      "{\n",
      "  \"module_dict\": {\n",
      "    \"bn_input\": {\n",
      "      \"name\": \"torch.nn.batchnorm2d\",\n",
      "      \"params\": {\n",
      "        \"num_features\": 1,\n",
      "        \"eps\": 0.001,\n",
      "        \"momentum\": 0.1,\n",
      "        \"affine\": true\n",
      "      },\n",
      "      \"init\": {}\n",
      "    },\n",
      "    \"bl_stack\": {\n",
      "      \"name\": \"rcnn_kriegeskorte.blstack\",\n",
      "      \"params\": {\n",
      "        \"n_timesteps\": 8,\n",
      "        \"channel_list\": [\n",
      "          1,\n",
      "          48,\n",
      "          48,\n",
      "          48\n",
      "        ],\n",
      "        \"ksize_list\": [\n",
      "          13,\n",
      "          3,\n",
      "          3\n",
      "        ],\n",
      "        \"pool_ksize\": 1,\n",
      "        \"pool_type\": null,\n",
      "        \"act_fn\": \"softplus\"\n",
      "      },\n",
      "      \"init\": {\n",
      "        \"strategy\": \"normal\",\n",
      "        \"parameters\": {\n",
      "          \"std\": 0.01\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"accumulator\": {\n",
      "      \"name\": \"rcnn_kriegeskorte.accumulator\",\n",
      "      \"params\": {\n",
      "        \"mode\": \"cummean\"\n",
      "      },\n",
      "      \"init\": null\n",
      "    },\n",
      "    \"pooling\": {\n",
      "      \"name\": \"torch.nn.maxpool2d\",\n",
      "      \"params\": {\n",
      "        \"kernel_size\": 2,\n",
      "        \"ceil_mode\": true\n",
      "      },\n",
      "      \"init\": null\n",
      "    },\n",
      "    \"fc\": {\n",
      "      \"name\": \"maskcnn.factoredfc\",\n",
      "      \"params\": {\n",
      "        \"in_channels\": 48,\n",
      "        \"map_size\": [\n",
      "          25,\n",
      "          25\n",
      "        ],\n",
      "        \"out_features\": 3,\n",
      "        \"bias\": true,\n",
      "        \"weight_feature_constraint\": null,\n",
      "        \"weight_spatial_constraint\": null\n",
      "      },\n",
      "      \"init\": {\n",
      "        \"strategy\": \"normal\",\n",
      "        \"parameters\": {\n",
      "          \"std\": 0.01\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"final_act\": {\n",
      "      \"name\": \"torch.nn.softplus\",\n",
      "      \"params\": {},\n",
      "      \"init\": null\n",
      "    }\n",
      "  },\n",
      "  \"op_list\": [\n",
      "    {\n",
      "      \"name\": \"sequential\",\n",
      "      \"args\": [\n",
      "        [\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"bn_input\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"bl_stack\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"accumulator\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      ],\n",
      "      \"kwargs\": {},\n",
      "      \"in\": \"input0\",\n",
      "      \"out\": \"feature_map\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"sequential\",\n",
      "      \"args\": [\n",
      "        [\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"pooling\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"fc\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"final_act\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          }\n",
      "        ]\n",
      "      ],\n",
      "      \"kwargs\": {},\n",
      "      \"in\": \"feature_map\",\n",
      "      \"out\": \"out_neural_separate\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"stack\",\n",
      "      \"args\": [],\n",
      "      \"kwargs\": {\n",
      "        \"dim\": 0\n",
      "      },\n",
      "      \"in\": \"out_neural_separate\",\n",
      "      \"out\": \"out_neural\"\n",
      "    }\n",
      "  ],\n",
      "  \"out\": [\n",
      "    \"out_neural\"\n",
      "  ],\n",
      "  \"comments\": {\n",
      "    \"conv_layers\": [\n",
      "      \"bl_stack.layer_list.0.b_conv\",\n",
      "      \"bl_stack.layer_list.1.b_conv\",\n",
      "      \"bl_stack.layer_list.2.b_conv\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "JSONNet(\n",
      "  (moduledict): ModuleDict(\n",
      "    (accumulator): RecurrentAccumulator()\n",
      "    (bl_stack): BLConvLayerStack(\n",
      "      (layer_list): ModuleList(\n",
      "        (0): BLConvLayer(\n",
      "          (b_conv): Conv2d(1, 48, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), bias=False)\n",
      "          (l_conv): Conv2d(48, 48, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), bias=False)\n",
      "        )\n",
      "        (1): BLConvLayer(\n",
      "          (b_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (l_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BLConvLayer(\n",
      "          (b_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (l_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bn_layer_list): ModuleList(\n",
      "        (0): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (8): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (9): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (10): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (11): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (12): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (13): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (14): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (15): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (16): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (17): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (18): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (19): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (20): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (21): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (22): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (23): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act_fn): Softplus(beta=1, threshold=20)\n",
      "      (pool): Identity()\n",
      "    )\n",
      "    (bn_input): BatchNorm2d(1, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc): FactoredLinear2D()\n",
      "    (final_act): Softplus(beta=1, threshold=20)\n",
      "    (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      ")\n",
      "moduledict.bl_stack.layer_list.0.b_conv.weight torch.Size([48, 1, 13, 13]) tensor(1.4950e-05) tensor(0.0101)\n",
      "moduledict.bl_stack.layer_list.0.l_conv.weight torch.Size([48, 48, 13, 13]) tensor(-8.2972e-06) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.1.b_conv.weight torch.Size([48, 48, 3, 3]) tensor(5.7371e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.1.l_conv.weight torch.Size([48, 48, 3, 3]) tensor(-3.5611e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.2.b_conv.weight torch.Size([48, 48, 3, 3]) tensor(1.1117e-05) tensor(0.0099)\n",
      "moduledict.bl_stack.layer_list.2.l_conv.weight torch.Size([48, 48, 3, 3]) tensor(4.7878e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.bn_layer_list.0.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.0.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.1.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.1.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.2.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.2.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.3.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.3.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.4.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.4.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.5.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.5.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.6.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.6.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.7.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.7.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.8.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.8.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.9.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.9.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.10.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.10.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.11.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.11.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.12.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.12.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.13.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.13.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.14.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.14.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.15.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.15.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.16.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.16.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.17.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.17.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.18.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.18.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.19.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.19.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.20.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.20.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.21.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.21.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.22.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.22.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.23.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.23.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bn_input.weight torch.Size([1]) tensor(1.) tensor(nan)\n",
      "moduledict.bn_input.bias torch.Size([1]) tensor(0.) tensor(nan)\n",
      "moduledict.fc.weight_spatial torch.Size([3, 25, 25]) tensor(3.6120e-05) tensor(0.0103)\n",
      "moduledict.fc.weight_feature torch.Size([3, 48]) tensor(0.0007) tensor(0.0096)\n",
      "moduledict.fc.bias torch.Size([3]) tensor(0.) tensor(0.)\n",
      "{'final_act', 'fc', 'pooling', 'bn_output'}\n",
      "['out_neural_separate']\n",
      "{\n",
      "  \"module_dict\": {\n",
      "    \"bn_input\": {\n",
      "      \"name\": \"torch.nn.batchnorm2d\",\n",
      "      \"params\": {\n",
      "        \"num_features\": 1,\n",
      "        \"eps\": 0.001,\n",
      "        \"momentum\": 0.1,\n",
      "        \"affine\": true\n",
      "      },\n",
      "      \"init\": {}\n",
      "    },\n",
      "    \"bl_stack\": {\n",
      "      \"name\": \"rcnn_kriegeskorte.blstack\",\n",
      "      \"params\": {\n",
      "        \"n_timesteps\": 8,\n",
      "        \"channel_list\": [\n",
      "          1,\n",
      "          48,\n",
      "          48,\n",
      "          48\n",
      "        ],\n",
      "        \"ksize_list\": [\n",
      "          13,\n",
      "          3,\n",
      "          3\n",
      "        ],\n",
      "        \"pool_ksize\": 1,\n",
      "        \"pool_type\": null,\n",
      "        \"act_fn\": \"softplus\"\n",
      "      },\n",
      "      \"init\": {\n",
      "        \"strategy\": \"normal\",\n",
      "        \"parameters\": {\n",
      "          \"std\": 0.01\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"accumulator\": {\n",
      "      \"name\": \"rcnn_kriegeskorte.accumulator\",\n",
      "      \"params\": {\n",
      "        \"mode\": \"cummean\"\n",
      "      },\n",
      "      \"init\": null\n",
      "    },\n",
      "    \"pooling\": {\n",
      "      \"name\": \"torch.nn.maxpool2d\",\n",
      "      \"params\": {\n",
      "        \"kernel_size\": 2,\n",
      "        \"ceil_mode\": true\n",
      "      },\n",
      "      \"init\": null\n",
      "    },\n",
      "    \"fc\": {\n",
      "      \"name\": \"maskcnn.factoredfc\",\n",
      "      \"params\": {\n",
      "        \"in_channels\": 48,\n",
      "        \"map_size\": [\n",
      "          25,\n",
      "          25\n",
      "        ],\n",
      "        \"out_features\": 3,\n",
      "        \"bias\": true,\n",
      "        \"weight_feature_constraint\": null,\n",
      "        \"weight_spatial_constraint\": null\n",
      "      },\n",
      "      \"init\": {\n",
      "        \"strategy\": \"normal\",\n",
      "        \"parameters\": {\n",
      "          \"std\": 0.01\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"final_act\": {\n",
      "      \"name\": \"torch.nn.softplus\",\n",
      "      \"params\": {},\n",
      "      \"init\": null\n",
      "    }\n",
      "  },\n",
      "  \"op_list\": [\n",
      "    {\n",
      "      \"name\": \"sequential\",\n",
      "      \"args\": [\n",
      "        [\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"bn_input\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"bl_stack\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module\",\n",
      "            \"args\": [\n",
      "              \"accumulator\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"unpack\": false\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      ],\n",
      "      \"kwargs\": {},\n",
      "      \"in\": \"input0\",\n",
      "      \"out\": \"feature_map\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"sequential\",\n",
      "      \"args\": [\n",
      "        [\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"pooling\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"fc\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"module_repeat\",\n",
      "            \"args\": [\n",
      "              \"final_act\"\n",
      "            ],\n",
      "            \"kwargs\": {}\n",
      "          }\n",
      "        ]\n",
      "      ],\n",
      "      \"kwargs\": {},\n",
      "      \"in\": \"feature_map\",\n",
      "      \"out\": \"out_neural_separate\"\n",
      "    }\n",
      "  ],\n",
      "  \"out\": \"out_neural_separate\",\n",
      "  \"comments\": {\n",
      "    \"conv_layers\": [\n",
      "      \"bl_stack.layer_list.0.b_conv\",\n",
      "      \"bl_stack.layer_list.1.b_conv\",\n",
      "      \"bl_stack.layer_list.2.b_conv\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "JSONNet(\n",
      "  (moduledict): ModuleDict(\n",
      "    (accumulator): RecurrentAccumulator()\n",
      "    (bl_stack): BLConvLayerStack(\n",
      "      (layer_list): ModuleList(\n",
      "        (0): BLConvLayer(\n",
      "          (b_conv): Conv2d(1, 48, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), bias=False)\n",
      "          (l_conv): Conv2d(48, 48, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), bias=False)\n",
      "        )\n",
      "        (1): BLConvLayer(\n",
      "          (b_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (l_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BLConvLayer(\n",
      "          (b_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (l_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bn_layer_list): ModuleList(\n",
      "        (0): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (8): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (9): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (10): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (11): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (12): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (13): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (14): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (15): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (16): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (17): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (18): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (19): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (20): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (21): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (22): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (23): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act_fn): Softplus(beta=1, threshold=20)\n",
      "      (pool): Identity()\n",
      "    )\n",
      "    (bn_input): BatchNorm2d(1, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc): FactoredLinear2D()\n",
      "    (final_act): Softplus(beta=1, threshold=20)\n",
      "    (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      ")\n",
      "moduledict.bl_stack.layer_list.0.b_conv.weight torch.Size([48, 1, 13, 13]) tensor(1.4950e-05) tensor(0.0101)\n",
      "moduledict.bl_stack.layer_list.0.l_conv.weight torch.Size([48, 48, 13, 13]) tensor(-8.2972e-06) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.1.b_conv.weight torch.Size([48, 48, 3, 3]) tensor(5.7371e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.1.l_conv.weight torch.Size([48, 48, 3, 3]) tensor(-3.5611e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.layer_list.2.b_conv.weight torch.Size([48, 48, 3, 3]) tensor(1.1117e-05) tensor(0.0099)\n",
      "moduledict.bl_stack.layer_list.2.l_conv.weight torch.Size([48, 48, 3, 3]) tensor(4.7878e-05) tensor(0.0100)\n",
      "moduledict.bl_stack.bn_layer_list.0.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.0.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.1.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.1.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.2.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.2.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.3.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.3.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.4.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.4.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.5.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.5.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.6.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.6.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.7.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.7.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.8.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.8.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.9.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.9.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.10.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.10.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.11.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.11.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.12.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.12.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.13.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.13.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.14.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.14.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.15.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.15.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.16.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.16.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.17.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.17.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.18.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.18.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.19.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.19.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.20.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.20.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.21.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.21.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.22.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.22.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.23.weight torch.Size([48]) tensor(1.) tensor(0.)\n",
      "moduledict.bl_stack.bn_layer_list.23.bias torch.Size([48]) tensor(0.) tensor(0.)\n",
      "moduledict.bn_input.weight torch.Size([1]) tensor(1.) tensor(nan)\n",
      "moduledict.bn_input.bias torch.Size([1]) tensor(0.) tensor(nan)\n",
      "moduledict.fc.weight_spatial torch.Size([3, 25, 25]) tensor(3.6120e-05) tensor(0.0103)\n",
      "moduledict.fc.weight_feature torch.Size([3, 48]) tensor(0.0007) tensor(0.0096)\n",
      "moduledict.fc.bias torch.Size([3]) tensor(0.) tensor(0.)\n",
      "1 1\n",
      "torch.Size([8, 10, 3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8\n",
      "torch.Size([10, 3])\n"
     ]
    }
   ],
   "source": [
    "check_stack_vs_no_stack()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
