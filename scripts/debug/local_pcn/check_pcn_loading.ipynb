{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this notebook checks that model trained in <https://github.com/leelabcnbc/thesis-yimeng-v1/blob/25471e6e80f7acd0f2ec82bb9c577c58bfdd7171/3rdparty/PCN-with-Local-Recurrent-Processing/main_imagenet_fp16.py> can be loaded back from its checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms \n",
    "import torchvision.datasets as datasets\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from thesis_v2 import dir_dict, join\n",
    "from thesis_v2.models.pcn_local.reference import loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root': '/my_data/thesis-yimeng-v2',\n",
       " 'results': '/my_data/thesis-yimeng-v2/results',\n",
       " 'datasets': '/my_data/thesis-yimeng-v2/results/datasets',\n",
       " 'features': '/my_data/thesis-yimeng-v2/results/features',\n",
       " 'models': '/my_data/thesis-yimeng-v2/results/models',\n",
       " 'analyses': '/my_data/thesis-yimeng-v2/results/analyses',\n",
       " 'plots': '/my_data/thesis-yimeng-v2/results/plots',\n",
       " 'visualization': '/my_data/thesis-yimeng-v2/results/visualization',\n",
       " 'private_data': '/my_data/thesis-yimeng-v2/private_data',\n",
       " 'private_data_supp': '/my_data/thesis-yimeng-v2/private_data_supp',\n",
       " 'debug_data': '/my_data/thesis-yimeng-v2/debug_data',\n",
       " 'trash': '/my_data/thesis-yimeng-v2/trash'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'PredNetBpE_3CLS'\n"
     ]
    }
   ],
   "source": [
    "best_file = join(dir_dict['root'], '..', 'thesis-yimeng-v1', '3rdparty', 'PCN-with-Local-Recurrent-Processing', 'checkpoint', 'model_best.pth.tar.3CLS')\n",
    "trained_model, checkpoint = loader.load_pcn_imagenet('PredNetBpE', 3, checkpoint_path=best_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredNetBpE(\n",
       "  (baseconv): features2(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (featBN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (PcConvs): ModuleList(\n",
       "    (0): PcConvBp(\n",
       "      (FFconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (FBconv): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x64x1x1])\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (bypass): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (resp_init): Lambda()\n",
       "      (resp_loop): Lambda()\n",
       "    )\n",
       "    (1): PcConvBp(\n",
       "      (FFconv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (FBconv): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x128x1x1])\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (bypass): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (resp_init): Lambda()\n",
       "      (resp_loop): Lambda()\n",
       "    )\n",
       "    (2): PcConvBp(\n",
       "      (FFconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (FBconv): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x128x1x1])\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (bypass): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (resp_init): Lambda()\n",
       "      (resp_loop): Lambda()\n",
       "    )\n",
       "    (3): PcConvBp(\n",
       "      (FFconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (FBconv): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x128x1x1])\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (bypass): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (resp_init): Lambda()\n",
       "      (resp_loop): Lambda()\n",
       "    )\n",
       "    (4): PcConvBp(\n",
       "      (FFconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (FBconv): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x128x1x1])\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (bypass): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (resp_init): Lambda()\n",
       "      (resp_loop): Lambda()\n",
       "    )\n",
       "    (5): PcConvBp(\n",
       "      (FFconv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (FBconv): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x256x1x1])\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (bypass): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (resp_init): Lambda()\n",
       "      (resp_loop): Lambda()\n",
       "    )\n",
       "    (6): PcConvBp(\n",
       "      (FFconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (FBconv): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x256x1x1])\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (bypass): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (resp_init): Lambda()\n",
       "      (resp_loop): Lambda()\n",
       "    )\n",
       "    (7): PcConvBp(\n",
       "      (FFconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (FBconv): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x256x1x1])\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (bypass): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (resp_init): Lambda()\n",
       "      (resp_loop): Lambda()\n",
       "    )\n",
       "    (8): PcConvBp(\n",
       "      (FFconv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (FBconv): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x512x1x1])\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (bypass): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (resp_init): Lambda()\n",
       "      (resp_loop): Lambda()\n",
       "    )\n",
       "    (9): PcConvBp(\n",
       "      (FFconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (FBconv): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x512x1x1])\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (bypass): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (resp_init): Lambda()\n",
       "      (resp_loop): Lambda()\n",
       "    )\n",
       "    (10): PcConvBp(\n",
       "      (FFconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (FBconv): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x512x1x1])\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (bypass): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (resp_init): Lambda()\n",
       "      (resp_loop): Lambda()\n",
       "    )\n",
       "  )\n",
       "  (BNs): ModuleList(\n",
       "    (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  (maxpool2d): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (maxpool_dict): ModuleDict(\n",
       "    (2): Lambda()\n",
       "    (4): Lambda()\n",
       "    (6): Lambda()\n",
       "    (9): Lambda()\n",
       "  )\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (BNend): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc): Lambda()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok. let's create a validation set data loader, making sure we can get back that validation accuracy from\n",
    "# `checkpoint`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'name', 'state_dict', 'best_prec1', 'prec1', 'prec5', 'optimizer'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92, 74.838, 74.838, 92.232)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['epoch'], checkpoint['best_prec1'], checkpoint['prec1'], checkpoint['prec5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_loader():\n",
    "    valdir = join('/my_data_2/standard_datasets/ILSVRC2015/Data/CLS-LOC', 'val')\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(valdir, transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])),\n",
    "        # this batch size should be safe regardless of network type (3CLS or 5CLS)\n",
    "        batch_size=128, shuffle=False)\n",
    "    return val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, crop_num = 1):\n",
    "    batch_time = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    \n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            input = input.cuda(non_blocking=True)\n",
    "            target = target.cuda(non_blocking=True)\n",
    "#             input_var = input\n",
    "#             target_var = target\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "            top1.update(prec1.item(), input.size(0))\n",
    "            top5.update(prec5.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            \n",
    "            #print validation status with certain frequency 'print_freq'\n",
    "            if i % 10 == 0: \n",
    "                print('{0}-crop-validation\\t'\n",
    "                      'Test: [{1}/{2}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                      'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                       crop_num, i, len(val_loader), batch_time=batch_time,\n",
    "                       top1=top1, top5=top5))\n",
    "\n",
    "    print(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'\n",
    "          .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg, top5.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.enabled = True\n",
    "\n",
    "\n",
    "# the setting used in training.\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# # deterministic setting.\n",
    "# cudnn.benchmark = False\n",
    "# cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-crop-validation\tTest: [0/391]\tTime 4.491 (4.491)\tPrec@1 88.281 (88.281)\tPrec@5 96.875 (96.875)\n",
      "1-crop-validation\tTest: [10/391]\tTime 1.840 (1.873)\tPrec@1 75.781 (89.276)\tPrec@5 95.312 (97.372)\n",
      "1-crop-validation\tTest: [20/391]\tTime 1.535 (1.731)\tPrec@1 85.938 (84.003)\tPrec@5 95.312 (96.168)\n",
      "1-crop-validation\tTest: [30/391]\tTime 1.639 (1.683)\tPrec@1 80.469 (80.494)\tPrec@5 90.625 (95.312)\n",
      "1-crop-validation\tTest: [40/391]\tTime 1.561 (1.650)\tPrec@1 86.719 (82.698)\tPrec@5 92.969 (95.694)\n",
      "1-crop-validation\tTest: [50/391]\tTime 1.517 (1.641)\tPrec@1 95.312 (82.384)\tPrec@5 97.656 (95.374)\n",
      "1-crop-validation\tTest: [60/391]\tTime 1.475 (1.628)\tPrec@1 78.906 (83.376)\tPrec@5 91.406 (95.543)\n",
      "1-crop-validation\tTest: [70/391]\tTime 1.521 (1.617)\tPrec@1 74.219 (82.152)\tPrec@5 96.875 (95.412)\n",
      "1-crop-validation\tTest: [80/391]\tTime 1.538 (1.607)\tPrec@1 77.344 (81.414)\tPrec@5 96.875 (95.448)\n",
      "1-crop-validation\tTest: [90/391]\tTime 1.540 (1.600)\tPrec@1 74.219 (81.439)\tPrec@5 94.531 (95.441)\n",
      "1-crop-validation\tTest: [100/391]\tTime 1.484 (1.592)\tPrec@1 85.156 (81.157)\tPrec@5 96.094 (95.568)\n",
      "1-crop-validation\tTest: [110/391]\tTime 1.678 (1.592)\tPrec@1 57.812 (80.757)\tPrec@5 96.875 (95.573)\n",
      "1-crop-validation\tTest: [120/391]\tTime 1.560 (1.591)\tPrec@1 82.031 (80.927)\tPrec@5 97.656 (95.655)\n",
      "1-crop-validation\tTest: [130/391]\tTime 1.518 (1.592)\tPrec@1 94.531 (81.244)\tPrec@5 98.438 (95.670)\n",
      "1-crop-validation\tTest: [140/391]\tTime 1.559 (1.588)\tPrec@1 71.094 (81.145)\tPrec@5 96.094 (95.745)\n",
      "1-crop-validation\tTest: [150/391]\tTime 1.912 (1.590)\tPrec@1 70.312 (80.960)\tPrec@5 99.219 (95.695)\n",
      "1-crop-validation\tTest: [160/391]\tTime 1.623 (1.588)\tPrec@1 75.781 (80.838)\tPrec@5 94.531 (95.609)\n",
      "1-crop-validation\tTest: [170/391]\tTime 1.480 (1.584)\tPrec@1 60.156 (80.181)\tPrec@5 88.281 (95.303)\n",
      "1-crop-validation\tTest: [180/391]\tTime 1.528 (1.582)\tPrec@1 54.688 (79.614)\tPrec@5 87.500 (94.993)\n",
      "1-crop-validation\tTest: [190/391]\tTime 1.447 (1.581)\tPrec@1 61.719 (78.972)\tPrec@5 86.719 (94.629)\n",
      "1-crop-validation\tTest: [200/391]\tTime 1.364 (1.578)\tPrec@1 75.781 (78.401)\tPrec@5 93.750 (94.255)\n",
      "1-crop-validation\tTest: [210/391]\tTime 1.505 (1.576)\tPrec@1 74.219 (77.969)\tPrec@5 93.750 (94.105)\n",
      "1-crop-validation\tTest: [220/391]\tTime 1.553 (1.575)\tPrec@1 84.375 (77.835)\tPrec@5 97.656 (93.976)\n",
      "1-crop-validation\tTest: [230/391]\tTime 1.558 (1.575)\tPrec@1 64.062 (77.621)\tPrec@5 86.719 (93.875)\n",
      "1-crop-validation\tTest: [240/391]\tTime 1.524 (1.575)\tPrec@1 78.125 (77.619)\tPrec@5 92.969 (93.776)\n",
      "1-crop-validation\tTest: [250/391]\tTime 1.533 (1.571)\tPrec@1 79.688 (77.014)\tPrec@5 96.094 (93.523)\n",
      "1-crop-validation\tTest: [260/391]\tTime 1.558 (1.570)\tPrec@1 66.406 (76.592)\tPrec@5 91.406 (93.313)\n",
      "1-crop-validation\tTest: [270/391]\tTime 1.571 (1.569)\tPrec@1 56.250 (76.413)\tPrec@5 89.844 (93.194)\n",
      "1-crop-validation\tTest: [280/391]\tTime 1.498 (1.568)\tPrec@1 68.750 (76.251)\tPrec@5 92.969 (93.105)\n",
      "1-crop-validation\tTest: [290/391]\tTime 1.405 (1.567)\tPrec@1 48.438 (75.999)\tPrec@5 90.625 (92.955)\n",
      "1-crop-validation\tTest: [300/391]\tTime 1.482 (1.565)\tPrec@1 79.688 (75.844)\tPrec@5 92.969 (92.831)\n",
      "1-crop-validation\tTest: [310/391]\tTime 1.494 (1.565)\tPrec@1 75.000 (75.716)\tPrec@5 88.281 (92.707)\n",
      "1-crop-validation\tTest: [320/391]\tTime 1.507 (1.565)\tPrec@1 86.719 (75.579)\tPrec@5 95.312 (92.628)\n",
      "1-crop-validation\tTest: [330/391]\tTime 1.462 (1.563)\tPrec@1 57.812 (75.248)\tPrec@5 79.688 (92.433)\n",
      "1-crop-validation\tTest: [340/391]\tTime 1.598 (1.562)\tPrec@1 78.906 (75.133)\tPrec@5 96.875 (92.371)\n",
      "1-crop-validation\tTest: [350/391]\tTime 1.483 (1.562)\tPrec@1 77.344 (75.045)\tPrec@5 89.062 (92.294)\n",
      "1-crop-validation\tTest: [360/391]\tTime 1.620 (1.562)\tPrec@1 63.281 (74.786)\tPrec@5 89.844 (92.211)\n",
      "1-crop-validation\tTest: [370/391]\tTime 1.782 (1.565)\tPrec@1 67.188 (74.836)\tPrec@5 94.531 (92.270)\n",
      "1-crop-validation\tTest: [380/391]\tTime 1.573 (1.565)\tPrec@1 76.562 (74.785)\tPrec@5 93.750 (92.204)\n",
      "1-crop-validation\tTest: [390/391]\tTime 3.170 (1.570)\tPrec@1 45.000 (74.852)\tPrec@5 86.250 (92.240)\n",
      " * Prec@1 74.852 Prec@5 92.240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(74.852, 92.24)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cool, even higher.\n",
    "trained_model.cuda()\n",
    "validate(get_val_loader(), trained_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
