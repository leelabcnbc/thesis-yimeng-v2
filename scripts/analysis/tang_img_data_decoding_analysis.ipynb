{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this tries to quantify the amount of information in (0,100), (0,500), (400,500) sections of Gaya data on tang images.\n",
    "\n",
    "The methodology is similar to the one in the eLife sparse coding paper, using cross validation across trials.\n",
    "\n",
    "code adapted from https://github.com/leelabcnbc/sparse-coding-elife2018/blob/master/decoding/decoder_aux.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis_v2.data.prepared.gaya import get_neural_data as get_neural_data_gaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.model_selection import LeaveOneGroupOut, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(start_offset, end_offset, normalize):\n",
    "    neural_data = get_neural_data_gaya(dataset='tang',return_raw=True,start_offset=start_offset,end_offset=end_offset)\n",
    "    # for simplicity, I will just take first 8 trials\n",
    "    neural_data = np.asarray([x[:8] for x in neural_data])\n",
    "    # (num_time, num_trial, num_neuron)\n",
    "#     print(neural_data.shape)\n",
    "    assert neural_data.shape == (2250, 8, 34)\n",
    "    if normalize:\n",
    "        mean_data = neural_data.mean(axis=(0,1))\n",
    "        assert mean_data.shape == (34,)\n",
    "        neural_data = neural_data/mean_data\n",
    "    \n",
    "    return neural_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flat_data_label_and_group(data_all):\n",
    "    n_stim, max_trial, n_neuron = data_all.shape\n",
    "    # make the labels and group in shape (n_stim, max_trial)\n",
    "    # this is a rewrite of `get_n_trial_tang_data`\n",
    "    # from <https://github.com/leelabcnbc/sparse-coding-tang/blob/master/sct_code_python/preprocessing.py>\n",
    "\n",
    "    y_label = np.tile(np.arange(n_stim), max_trial)\n",
    "    y_group = np.repeat(np.arange(max_trial), n_stim)\n",
    "    # this follows the old way reshaping is done. essentially, first have all 1st trial data,\n",
    "    # then all 2nd trial, then all 3rd trial, etc.\n",
    "    x_flat = np.concatenate([data_all[:, i_trial, :] for i_trial in range(max_trial)], axis=0)\n",
    "\n",
    "    return x_flat, y_label, y_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_wrapper_one_Xy(X, y, y_group, n_jobs=-1):\n",
    "    # this only returns prediction.\n",
    "    assert len(X) == len(y)\n",
    "    cv_obj = _parse_cv_obj(X, y, y_group)\n",
    "    classifier = NearestCentroid()\n",
    "    # hack to change y. remember to do this before doing cv object. otherwise, stratified CV won't work.\n",
    "    # then classify, return prediction results.\n",
    "    y_pred = _classifier_return_pred(X, y, cv_obj, classifier,  n_jobs)\n",
    "    return y_pred\n",
    "\n",
    "def _classifier_return_pred(X, y, cv_obj, classifier, n_jobs):\n",
    "    y_pred = cross_val_predict(classifier, X, y, cv=cv_obj, n_jobs=n_jobs)\n",
    "    assert y.shape == y_pred.shape\n",
    "    return y_pred\n",
    "\n",
    "def _parse_cv_obj(X, y, y_group):\n",
    "    # if y_group is not None, then use LeaveOneGroupOut\n",
    "    # else, I will use StratifiedKFold\n",
    "    cv_obj = LeaveOneGroupOut().split(X, y, y_group)\n",
    "    return cv_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def everything_for_one(start_offset, end_offset, normalize):\n",
    "    print(f'{start_offset}-{end_offset}, normalize {normalize}')\n",
    "    data_all = get_data(start_offset,end_offset,normalize)\n",
    "    x_flat, y_label, y_group = get_flat_data_label_and_group(data_all)\n",
    "    y_pred = classification_wrapper_one_Xy(x_flat, y_label, y_group)\n",
    "    s = accuracy_score(y_pred, y_label)\n",
    "    assert s == (y_pred==y_label).mean()\n",
    "    print(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def everything():\n",
    "    df_all = []\n",
    "    for (start, end), normalize in product([(0, 500), (0, 400), (100, 500), (0, 100), (100, 200), (200, 300), (300, 400), (400, 500)],\n",
    "                                          [True, False]):\n",
    "        score = everything_for_one(start, end, normalize)\n",
    "        df_all.append(\n",
    "            {\n",
    "                'start': start,\n",
    "                'end': end,\n",
    "                'normalize': normalize,\n",
    "                'accuracy': score,\n",
    "            }\n",
    "        )\n",
    "    df = pd.DataFrame(df_all, columns=['start', 'end', 'normalize', 'accuracy'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-500, normalize True\n",
      "0.6485\n",
      "0-500, normalize False\n",
      "0.7176111111111111\n",
      "0-400, normalize True\n",
      "0.6212222222222222\n",
      "0-400, normalize False\n",
      "0.7049444444444445\n",
      "100-500, normalize True\n",
      "0.5489444444444445\n",
      "100-500, normalize False\n",
      "0.6134444444444445\n",
      "0-100, normalize True\n",
      "0.3262777777777778\n",
      "0-100, normalize False\n",
      "0.5516666666666666\n",
      "100-200, normalize True\n",
      "0.25483333333333336\n",
      "100-200, normalize False\n",
      "0.4062222222222222\n",
      "200-300, normalize True\n",
      "0.18266666666666667\n",
      "200-300, normalize False\n",
      "0.2807222222222222\n",
      "300-400, normalize True\n",
      "0.12527777777777777\n",
      "300-400, normalize False\n",
      "0.19361111111111112\n",
      "400-500, normalize True\n",
      "0.10355555555555555\n",
      "400-500, normalize False\n",
      "0.1455\n"
     ]
    }
   ],
   "source": [
    "dataframe = everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>normalize</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.648500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>False</td>\n",
       "      <td>0.717611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>True</td>\n",
       "      <td>0.621222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>False</td>\n",
       "      <td>0.704944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.548944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>500</td>\n",
       "      <td>False</td>\n",
       "      <td>0.613444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.326278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.551667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>True</td>\n",
       "      <td>0.254833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>0.406222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>0.182667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>False</td>\n",
       "      <td>0.280722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>300</td>\n",
       "      <td>400</td>\n",
       "      <td>True</td>\n",
       "      <td>0.125278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>300</td>\n",
       "      <td>400</td>\n",
       "      <td>False</td>\n",
       "      <td>0.193611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>400</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.103556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>400</td>\n",
       "      <td>500</td>\n",
       "      <td>False</td>\n",
       "      <td>0.145500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start  end  normalize  accuracy\n",
       "0       0  500       True  0.648500\n",
       "1       0  500      False  0.717611\n",
       "2       0  400       True  0.621222\n",
       "3       0  400      False  0.704944\n",
       "4     100  500       True  0.548944\n",
       "5     100  500      False  0.613444\n",
       "6       0  100       True  0.326278\n",
       "7       0  100      False  0.551667\n",
       "8     100  200       True  0.254833\n",
       "9     100  200      False  0.406222\n",
       "10    200  300       True  0.182667\n",
       "11    200  300      False  0.280722\n",
       "12    300  400       True  0.125278\n",
       "13    300  400      False  0.193611\n",
       "14    400  500       True  0.103556\n",
       "15    400  500      False  0.145500"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe\n",
    "# 1. normalize is bad.\n",
    "# 2. later responses have less info\n",
    "# 3. full response has most info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
