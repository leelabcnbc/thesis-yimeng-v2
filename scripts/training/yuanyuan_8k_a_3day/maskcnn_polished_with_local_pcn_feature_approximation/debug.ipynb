{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this notebook sees how to create a feedforward approximator for recurrent features extracted in `scripts/feature_extraction/yuanyuan_8k_a/maskcnn_polished_with_local_pcn/debug.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common libs\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "from sys import path\n",
    "from os.path import join\n",
    "\n",
    "\n",
    "from thesis_v2 import dir_dict\n",
    "\n",
    "from torchnetjson.builder import build_net\n",
    "from thesis_v2.training.training_aux import load_training_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_to_check = 'scripts/feature_extraction/yuanyuan_8k_a/maskcnn_polished_with_local_pcn'\n",
    "path.insert(0, join(dir_dict['root'], folder_to_check))\n",
    "from certain_configs import get_all_model_params, global_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_file_dir': '/my_data/thesis-yimeng-v2/results/features/maskcnn_polished_with_local_pcn/certain_configs', 'augment_config': {'module_names': ['bottomup', 'topdown', 'final'], 'name_mapping': {'moduledict.conv1.lambda_out': 'bottomup', 'moduledict.conv1.lambda_in': 'topdown', 'moduledict.final_act': 'final'}}}\n"
     ]
    }
   ],
   "source": [
    "print(global_vars)\n",
    "\n",
    "# utils\n",
    "def get_layer_idx(friendly_name):\n",
    "    return global_vars['augment_config']['module_names'].index(friendly_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all model params\n",
    "all_params_dict = get_all_model_params()\n",
    "\n",
    "# same one as in `scripts/feature_extraction/yuanyuan_8k_a/maskcnn_polished_with_local_pcn/debug.ipynb`\n",
    "model_to_check = 's_selegacy+in_sz50+out_ch16+num_l2+k_l19+k_p3+ptavg+bn_b_actTrue+bn_a_fcFalse+actrelu+p_c5+p_bypassFalse+p_n_actFalse+p_bn_pFalse+p_actTrue+p_bnTrue+p_biasTrue+sc0.01+sm0.000005+lmse+m_se0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract input 'topdown.0' as well as all 'bottomup.*' except the last one.\n",
    "\n",
    "def fetch_data(feature_file, grp_name):\n",
    "    # let's collect first 10 images' responses for verification.\n",
    "    slice_to_check = slice(0, 256)\n",
    "    with h5py.File(feature_file, 'r') as f_feature:\n",
    "        grp = f_feature[grp_name]\n",
    "        num_bottom_up = len([x for x in grp if x.startswith(str(get_layer_idx('bottomup')) + '.')])\n",
    "        assert num_bottom_up > 2\n",
    "        \n",
    "        pcn_in = grp[str(get_layer_idx('topdown')) + '.0'][slice_to_check]\n",
    "        pcn_out_list = [grp[str(get_layer_idx('bottomup')) + f'.{x}'][slice_to_check] for x in range(num_bottom_up-1)]\n",
    "    \n",
    "    print((pcn_in.shape, pcn_in.mean(), pcn_in.std(), pcn_in.min(), pcn_in.max()))\n",
    "    print([(x.shape, x.mean(), x.std(), x.min(), x.max()) for x in pcn_out_list])\n",
    "    \n",
    "    return {\n",
    "        'in': pcn_in,\n",
    "        'out_list': pcn_out_list,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((256, 16, 42, 42), 0.35897052, 0.5706741, 0.0, 11.922759)\n",
      "[((256, 16, 42, 42), 0.2553295, 0.42159, 0.0, 8.292999), ((256, 16, 42, 42), 0.27825132, 0.7672202, -4.185834, 13.933849), ((256, 16, 42, 42), 0.29259625, 1.0237633, -6.97853, 16.669125), ((256, 16, 42, 42), 0.3059992, 1.3043457, -9.800613, 19.26218), ((256, 16, 42, 42), 0.31785125, 1.650338, -13.161419, 21.148617), ((256, 16, 42, 42), 0.32922515, 2.0893815, -17.23216, 24.323668)]\n"
     ]
    }
   ],
   "source": [
    "data_returned = fetch_data(join(global_vars['feature_file_dir'], model_to_check + '.hdf5'), 'X_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "def load_model(key):\n",
    "    result = load_training_results(key, return_model=False)\n",
    "    # load twice, first time to get the model.\n",
    "    model_ = load_training_results(key, return_model=True, model=build_net(result['config_extra']['model']))['model']\n",
    "    model_.cuda()\n",
    "    model_.eval()\n",
    "    return model_\n",
    "\n",
    "model = load_model(all_params_dict[model_to_check]['key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1)\n",
      "0.022921672 0.42046013 -4.185834 6.33709\n",
      "0.0\n",
      "0.0\n",
      "(0, 2)\n",
      "0.037266962 0.720724 -6.97853 10.422319\n",
      "0.0\n",
      "0.0\n",
      "(0, 3)\n",
      "0.05066977 1.0387783 -9.800613 13.015375\n",
      "0.0\n",
      "0.0\n",
      "(0, 4)\n",
      "0.06252189 1.4155142 -13.161419 15.393248\n",
      "0.0\n",
      "0.0\n",
      "(0, 5)\n",
      "0.073895715 1.8798158 -17.23216 17.793856\n",
      "0.0\n",
      "0.0\n",
      "(1, 2)\n",
      "0.014345304 0.33172116 -2.8825576 4.222127\n",
      "0.0\n",
      "0.0\n",
      "(1, 3)\n",
      "0.02774809 0.68103695 -6.032793 7.5598173\n",
      "0.0\n",
      "0.0\n",
      "(1, 4)\n",
      "0.0396002 1.0860796 -9.664015 9.994712\n",
      "0.0\n",
      "0.0\n",
      "(1, 5)\n",
      "0.050974116 1.5759 -14.066785 14.17896\n",
      "0.0\n",
      "0.0\n",
      "(2, 3)\n",
      "0.013402778 0.35958126 -3.1581278 3.3376904\n",
      "0.0\n",
      "0.0\n",
      "(2, 4)\n",
      "0.02525489 0.778254 -6.9140663 6.851712\n",
      "0.0\n",
      "0.0\n",
      "(2, 5)\n",
      "0.03662875 1.2837849 -11.316836 12.893453\n",
      "0.0\n",
      "0.0\n",
      "(3, 4)\n",
      "0.01185211 0.42521432 -3.7559385 4.227053\n",
      "0.0\n",
      "0.0\n",
      "(3, 5)\n",
      "0.023225963 0.9418687 -8.158709 10.268793\n",
      "0.0\n",
      "0.0\n",
      "(4, 5)\n",
      "0.011373837 0.52283007 -4.40277 6.144558\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# # the idea is, given idx1 and idx2, predict out_list[idx2] - out_list[idx1]  given (out_list[idx1]  and in).\n",
    "\n",
    "from numpy.linalg import norm\n",
    "from torch.backends import cudnn\n",
    "import torch\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = False\n",
    "def check_similarity(d1, d2):\n",
    "    assert d1.shape == d2.shape\n",
    "    norm_diff = norm(d1-d2)/norm(d2)\n",
    "    print(norm_diff)\n",
    "    print(abs(d1-d2).max())\n",
    "    assert norm_diff < 1e-5\n",
    "\n",
    "def debug_result(model_,in_,out1,idx_diff):\n",
    "    assert idx_diff > 0\n",
    "    out_now = out1\n",
    "    with torch.no_grad():\n",
    "        for _ in range(idx_diff):\n",
    "            pred_now = model.moduledict['conv1'].forward_fb(\n",
    "                torch.tensor(out_now).cuda(),\n",
    "            ).cpu().numpy()\n",
    "            out_now = model.moduledict['conv1'].forward_update(\n",
    "                torch.tensor(out_now).cuda(),\n",
    "                torch.tensor(in_).cuda(),\n",
    "                torch.tensor(pred_now).cuda(),\n",
    "            ).cpu().numpy()\n",
    "    return out_now - out1\n",
    "\n",
    "def check_result(model_, data_dict):\n",
    "    num_out = len(data_dict['out_list'])\n",
    "    \n",
    "    for idx1 in range(num_out):\n",
    "        for idx2 in range(idx1+1, num_out):\n",
    "            print((idx1, idx2))\n",
    "            result_ref = data_dict['out_list'][idx2] - data_dict['out_list'][idx1]\n",
    "            print(result_ref.mean(), result_ref.std(), result_ref.min(), result_ref.max())\n",
    "            result_debug = debug_result(model_,data_dict['in'],data_dict['out_list'][idx1],idx2-idx1)\n",
    "            check_similarity(result_ref, result_debug)\n",
    "\n",
    "# all ok.\n",
    "check_result(model, data_returned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now time to get a model to train it.\n",
    "# simple stuff. conv + relu.\n",
    "# maybe with BN.\n",
    "\n",
    "# two kinds of models\n",
    "\n",
    "# BN + conv + ReLU + BN\n",
    "# conv + ReLU + BN\n",
    "# I may want to constrain the first BN a bit,\n",
    "# say, all in_ channels share the same scale and bias; same goes with out1 channels.\n",
    "\n",
    "# some concerns: stats are different for `out_` at different iterations.\n",
    "# but let's ignore it for now."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
