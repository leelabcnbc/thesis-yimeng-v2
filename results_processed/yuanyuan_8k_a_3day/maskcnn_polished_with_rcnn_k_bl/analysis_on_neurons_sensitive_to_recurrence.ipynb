{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis_v2 import dir_dict\n",
    "from os.path import join\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis_v2.configs.model.maskcnn_polished_with_rcnn_k_bl import (\n",
    "    explored_models_20200218 as param_iterator_obj_k_bl,\n",
    "    keygen as keygen_k_bl\n",
    ")\n",
    "\n",
    "from thesis_v2.configs.model.maskcnn_polished_with_local_pcn import (\n",
    "    explored_models_summer_2019_certain as param_iterator_obj_local_pcn,\n",
    "    keygen as keygen_local_pcn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis_v2.data.prepared.yuanyuan_8k import get_data, get_indices, get_neural_data\n",
    "from thesis_v2.data.raw import load_data\n",
    "from thesis_v2.training.training_aux import load_training_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: verify my param_iterator_obj_local_pcn is the same as the original one.\n",
    "# well, you can achieve this by comparing the output of \n",
    "# scripts/training/yuanyuan_8k_a_3day/maskcnn_polished_with_local_pcn/submit_certain_configs_refactored.py\n",
    "# AND\n",
    "# scripts/training/yuanyuan_8k_a_3day/maskcnn_polished_with_local_pcn/submit_certain_configs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_vars = {\n",
    "    'cases': {\n",
    "        'k_bl': {\n",
    "            'metric_file': join(dir_dict['analyses'],\n",
    "                                'metrics_yuanyuan_8k_a_3day+maskcnn_polished_with_rcnn_k_bl+20200218.pkl'),\n",
    "            'param_iterator': param_iterator_obj_k_bl,\n",
    "            'keygen': keygen_k_bl,\n",
    "            'cls_level': 'rcnn_bl_cls',\n",
    "            'base_key': 2,\n",
    "            'improved_key': 4,\n",
    "            'fc_size': 14,\n",
    "            'dir_response': join(\n",
    "                dir_dict['analyses'],\n",
    "                'responses_yuanyuan_8k_a_3day+maskcnn_polished_with_rcnn_k_bl+20200218'\n",
    "            ),\n",
    "        },\n",
    "        'local_pcn_50': {\n",
    "            'metric_file': join(dir_dict['analyses'],\n",
    "                                'metrics_yuanyuan_8k_a_3day+maskcnn_polished_with_local_pcn+certain_configs.pkl'),\n",
    "            'metric_filter': {'input_size': 50},\n",
    "            'param_iterator': param_iterator_obj_local_pcn,\n",
    "            'param_filter': lambda x: x['input_size'] == 50,\n",
    "            'keygen': keygen_local_pcn,\n",
    "            'cls_level': 'pcn_cls',\n",
    "            'base_key': 1,\n",
    "            'improved_key': (2,3,4,5),\n",
    "            'fc_size': 14,\n",
    "            'dir_response': join(\n",
    "                dir_dict['analyses'],\n",
    "                'responses_yuanyuan_8k_a_3day+maskcnn_polished_with_local_pcn+certain_configs'\n",
    "            ),\n",
    "        },\n",
    "        'local_pcn_100': {\n",
    "            'metric_file': join(dir_dict['analyses'],\n",
    "                                'metrics_yuanyuan_8k_a_3day+maskcnn_polished_with_local_pcn+certain_configs.pkl'),\n",
    "            # only use subset of rows, using pd.DataFrame.xs\n",
    "            'metric_filter': {'input_size': 100},\n",
    "            'param_iterator': param_iterator_obj_local_pcn,\n",
    "            'param_filter': lambda x: x['input_size'] == 100,\n",
    "            'keygen': keygen_local_pcn,\n",
    "            'cls_level': 'pcn_cls',\n",
    "            'base_key': 1,\n",
    "            'improved_key': (2,3,4,5),\n",
    "            'fc_size': 31,\n",
    "            'dir_response': join(\n",
    "                dir_dict['analyses'],\n",
    "                'responses_yuanyuan_8k_a_3day+maskcnn_polished_with_local_pcn+certain_configs'\n",
    "            ),\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shared_ground_truth(debug=False):\n",
    "    # load neural reponses on all.\n",
    "    neural_data = get_neural_data(('042318', '043018', '051018'), scale=0.5)\n",
    "    idx_train, idx_val, idx_test = get_indices('a', 'legacy')\n",
    "    images = load_data('yuanyuan_8k_images', 'a')['images']\n",
    "    \n",
    "    print(neural_data.shape, images.shape)\n",
    "    \n",
    "    if debug:\n",
    "        data_gt = get_data('a', 200, 50,\n",
    "                 ('042318', '043018', '051018'),\n",
    "                 scale=0.5,\n",
    "                 seed='legacy')\n",
    "\n",
    "\n",
    "        assert np.array_equal(data_gt[5], neural_data[idx_test])\n",
    "        assert np.array_equal(data_gt[3], neural_data[idx_val])\n",
    "        assert np.array_equal(data_gt[1], neural_data[idx_train])\n",
    "\n",
    "    return {\n",
    "        'neural_data': neural_data,\n",
    "        'idx_train': idx_train,\n",
    "        'idx_val': idx_val,\n",
    "        'idx_test': idx_test,\n",
    "        'images': images,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/my_data/thesis-yimeng-v2/results/analyses/responses_yuanyuan_8k_a_3day+maskcnn_polished_with_rcnn_k_bl+20200218/yuanyuan_8k_a_3day/maskcnn_polished_with_local_pcn/s_selegacy/in_sz50/out_ch16/num_l2/k_l19/k_p3/ptavg/bn_b_actTrue/bn_a_fcFalse/actrelu/p_c0/p_bypassFalse/p_n_actFalse/p_bn_pFalse/p_actTrue/p_bnTrue/p_biasTrue/sc0.01/sm0.000005/lmse/m_se0/test.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-df99ddf240f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m     }\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mload_ground_truth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mglobal_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cases'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_pcn_50'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-df99ddf240f3>\u001b[0m in \u001b[0;36mload_ground_truth\u001b[0;34m(case_name, case_config)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mfile_to_load_this\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_to_load_this\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m79\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/leelab/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/my_data/thesis-yimeng-v2/results/analyses/responses_yuanyuan_8k_a_3day+maskcnn_polished_with_rcnn_k_bl+20200218/yuanyuan_8k_a_3day/maskcnn_polished_with_local_pcn/s_selegacy/in_sz50/out_ch16/num_l2/k_l19/k_p3/ptavg/bn_b_actTrue/bn_a_fcFalse/actrelu/p_c0/p_bypassFalse/p_n_actFalse/p_bn_pFalse/p_actTrue/p_bnTrue/p_biasTrue/sc0.01/sm0.000005/lmse/m_se0/test.npy'"
     ]
    }
   ],
   "source": [
    "def load_ground_truth(case_name, case_config):\n",
    "    \n",
    "    # load neural responses on test data.\n",
    "    # go over each config,\n",
    "    # load responses on test data, collected over each cls.\n",
    "    # load masks averaged over all configs.\n",
    "    \n",
    "    param_iterator_obj = case_config['param_iterator']\n",
    "    keygen = case_config['keygen']\n",
    "    fc_size = case_config['fc_size']\n",
    "    dir_response = case_config['dir_response']\n",
    "    \n",
    "    rf_map_all = []\n",
    "    \n",
    "    response_map = {}\n",
    "    param_filter = case_config.get('param_filter', lambda _: True)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    \n",
    "    for idx, param in enumerate(param_iterator_obj().generate()):\n",
    "        if idx % 20 == 0:\n",
    "            print(idx)\n",
    "        if not param_filter(param):\n",
    "            continue\n",
    "        count += 1\n",
    "        key = keygen(**{k: v for k, v in param.items() if k not in {'scale', 'smoothness'}})\n",
    "        \n",
    "        # load model params.\n",
    "        result = load_training_results(key, return_model=False,return_checkpoint=True)\n",
    "        rf_map = result['checkpoint']['model']['moduledict.fc.weight_spatial'].numpy()\n",
    "        assert rf_map.shape == (79, fc_size, fc_size)\n",
    "        \n",
    "        rf_map = abs(rf_map)\n",
    "        # make each mask sum to one.\n",
    "        rf_map = rf_map/np.sum(rf_map,axis=(1,2),keepdims=True)\n",
    "#         print(rf_map.sum())\n",
    "        rf_map_all.append(rf_map)\n",
    "    \n",
    "    \n",
    "        # get response.\n",
    "        file_to_load_this = join(dir_response, key, 'test' + '.npy')\n",
    "        resp = np.load(file_to_load_this)\n",
    "        assert resp.shape == (1600, 79)\n",
    "        \n",
    "        \n",
    "        cls_this = param[case_config['cls_level']]\n",
    "        if cls_this not in response_map:\n",
    "            response_map[cls_this] = []\n",
    "            \n",
    "        response_map[cls_this].append(resp)\n",
    "    \n",
    "    for cls_value in response_map:\n",
    "        response_map[cls_value] = np.asarray(response_map[cls_value])\n",
    "    \n",
    "    for kk, vv in response_map.items():\n",
    "        print(kk, vv.shape)\n",
    "    \n",
    "    # average over all normalized map\n",
    "    rf_map_all = np.asarray(rf_map_all).mean(axis=0)\n",
    "#     print(rf_map_all.sum())\n",
    "    print(rf_map_all.shape)\n",
    "\n",
    "    return {\n",
    "        'nunm_cases': count,\n",
    "        # all 79 maps.\n",
    "        'rf_map': rf_map_all,\n",
    "    }\n",
    "    \n",
    "load_ground_truth(None,global_vars['cases']['local_pcn_50'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n",
      "300\n",
      "320\n",
      "340\n",
      "360\n",
      "380\n",
      "400\n",
      "420\n",
      "440\n",
      "460\n",
      "480\n",
      "500\n",
      "520\n",
      "540\n",
      "560\n",
      "580\n",
      "600\n",
      "620\n",
      "640\n",
      "660\n",
      "680\n",
      "700\n",
      "720\n",
      "740\n",
      "760\n",
      "780\n",
      "800\n",
      "820\n",
      "840\n",
      "860\n",
      "880\n",
      "900\n",
      "920\n",
      "940\n",
      "960\n",
      "980\n",
      "1000\n",
      "1020\n",
      "1040\n",
      "1060\n",
      "1080\n",
      "1100\n",
      "1120\n",
      "1140\n",
      "1160\n",
      "1180\n",
      "1200\n",
      "1220\n",
      "1240\n",
      "1260\n",
      "1280\n",
      "1300\n",
      "1320\n",
      "1340\n",
      "1360\n",
      "1380\n",
      "1400\n",
      "1420\n",
      "1440\n",
      "1460\n",
      "1480\n",
      "1500\n",
      "1520\n",
      "1540\n",
      "1560\n",
      "1580\n",
      "1600\n",
      "1620\n",
      "1640\n",
      "1660\n",
      "1680\n",
      "1700\n",
      "1720\n",
      "1740\n",
      "1760\n",
      "1780\n",
      "1800\n",
      "1820\n",
      "1840\n",
      "1860\n",
      "1880\n",
      "1900\n",
      "1920\n",
      "1940\n",
      "1960\n",
      "1980\n",
      "2000\n",
      "2020\n",
      "2040\n",
      "2060\n",
      "2080\n",
      "2100\n",
      "2120\n",
      "2140\n",
      "2160\n",
      "2180\n",
      "2200\n",
      "2220\n",
      "2240\n",
      "2260\n",
      "2280\n",
      "2300\n",
      "0 (192, 1600, 79)\n",
      "1 (192, 1600, 79)\n",
      "2 (192, 1600, 79)\n",
      "3 (192, 1600, 79)\n",
      "4 (192, 1600, 79)\n",
      "5 (192, 1600, 79)\n",
      "(79, 31, 31)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nunm_cases': 1152,\n",
       " 'rf_map': array([[[9.60995851e-04, 3.13948095e-03, 4.78348549e-04, ...,\n",
       "          3.72561975e-04, 3.78090335e-04, 4.11142450e-04],\n",
       "         [4.60950250e-04, 6.13679353e-04, 2.92069861e-04, ...,\n",
       "          1.66415062e-03, 2.25735130e-04, 1.90143022e-04],\n",
       "         [2.22078263e-04, 2.59687105e-04, 2.50283891e-04, ...,\n",
       "          8.09564022e-04, 3.11436015e-04, 2.01943592e-04],\n",
       "         ...,\n",
       "         [3.40137485e-04, 4.45728394e-04, 2.59066437e-04, ...,\n",
       "          3.42535757e-04, 8.11291859e-03, 4.84541385e-03],\n",
       "         [3.97733995e-04, 2.91021803e-04, 5.79404819e-04, ...,\n",
       "          2.88065698e-04, 3.91666498e-03, 2.11987947e-03],\n",
       "         [2.54744955e-04, 3.34982644e-04, 4.86117846e-04, ...,\n",
       "          3.62338353e-04, 1.74468150e-03, 4.14092210e-04]],\n",
       " \n",
       "        [[4.59937059e-04, 1.95439818e-04, 1.49128027e-04, ...,\n",
       "          2.33823404e-04, 2.93978403e-04, 4.02704463e-04],\n",
       "         [1.89184822e-04, 4.33573150e-04, 1.30390195e-04, ...,\n",
       "          2.58776156e-04, 6.46605389e-04, 5.44618582e-04],\n",
       "         [2.38643552e-04, 2.43031024e-03, 2.73135112e-04, ...,\n",
       "          1.95009256e-04, 1.42708537e-03, 5.56146842e-04],\n",
       "         ...,\n",
       "         [5.47939155e-04, 1.52498091e-04, 2.76142382e-04, ...,\n",
       "          4.43796045e-04, 1.38979265e-03, 1.06531149e-03],\n",
       "         [4.82074131e-04, 3.30109731e-04, 4.65690886e-04, ...,\n",
       "          2.91945325e-04, 3.69030284e-04, 5.85777918e-04],\n",
       "         [2.94412894e-04, 5.85857197e-04, 5.69200434e-04, ...,\n",
       "          6.26220310e-04, 3.20416206e-04, 3.09411058e-04]],\n",
       " \n",
       "        [[8.34646198e-05, 4.78304311e-04, 4.06694249e-04, ...,\n",
       "          1.35577488e-04, 1.17324264e-04, 1.55163347e-04],\n",
       "         [1.28902859e-04, 1.90706560e-04, 1.64181969e-04, ...,\n",
       "          2.63187569e-04, 1.40283169e-04, 2.50100304e-04],\n",
       "         [1.82706455e-04, 3.80971585e-04, 1.93133586e-04, ...,\n",
       "          1.67178907e-04, 1.48282808e-04, 2.65870447e-04],\n",
       "         ...,\n",
       "         [1.25790291e-04, 1.18027761e-04, 1.50132953e-04, ...,\n",
       "          1.47331913e-04, 1.31859226e-04, 1.36979099e-04],\n",
       "         [4.88617574e-04, 4.09398664e-04, 1.31775465e-04, ...,\n",
       "          1.50000807e-04, 2.51206569e-04, 2.51964724e-04],\n",
       "         [6.30679540e-04, 3.04382149e-04, 8.96331403e-05, ...,\n",
       "          1.34802845e-04, 1.57964590e-04, 1.89813567e-04]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.19246426e-03, 5.71021985e-04, 4.03095852e-04, ...,\n",
       "          4.43865196e-04, 3.73373216e-04, 2.30251506e-04],\n",
       "         [1.36421248e-03, 1.23540557e-03, 3.56309640e-04, ...,\n",
       "          7.34731788e-04, 4.98943380e-04, 2.46721553e-04],\n",
       "         [3.16322985e-04, 2.32711973e-04, 1.25635474e-04, ...,\n",
       "          4.97721834e-04, 1.76538219e-04, 5.22295828e-04],\n",
       "         ...,\n",
       "         [2.41136542e-04, 3.88100918e-04, 2.40259309e-04, ...,\n",
       "          1.77551829e-03, 4.13704780e-04, 1.87692669e-04],\n",
       "         [3.69970279e-04, 6.28675683e-04, 1.62402727e-03, ...,\n",
       "          3.68564448e-04, 4.44775709e-04, 3.68402048e-04],\n",
       "         [2.15123073e-04, 3.52154369e-04, 4.45418380e-04, ...,\n",
       "          5.10618673e-04, 7.69588340e-04, 3.97169148e-04]],\n",
       " \n",
       "        [[1.16296159e-03, 7.38244737e-04, 1.01670099e-03, ...,\n",
       "          3.44146305e-04, 3.88913351e-04, 4.88417747e-04],\n",
       "         [6.24447770e-04, 2.95037258e-04, 1.91715240e-04, ...,\n",
       "          2.93413585e-04, 2.53843493e-04, 1.80004619e-03],\n",
       "         [9.20465915e-04, 1.98192996e-04, 1.47551182e-04, ...,\n",
       "          4.51668573e-04, 2.44816940e-04, 4.64899349e-04],\n",
       "         ...,\n",
       "         [5.83225454e-04, 2.88301473e-03, 3.55860015e-04, ...,\n",
       "          1.21032605e-02, 4.55491757e-03, 8.11812468e-03],\n",
       "         [4.32501605e-04, 3.83666542e-04, 3.03690642e-04, ...,\n",
       "          9.61377099e-03, 8.66274722e-03, 8.10427219e-03],\n",
       "         [1.18530472e-03, 5.26792137e-04, 4.33335634e-04, ...,\n",
       "          8.33149534e-03, 7.08808191e-03, 5.11484407e-03]],\n",
       " \n",
       "        [[4.59342264e-04, 5.20173577e-04, 2.52071477e-04, ...,\n",
       "          1.80027244e-04, 3.93344963e-04, 1.79371389e-04],\n",
       "         [1.74343324e-04, 1.67961785e-04, 1.77826121e-04, ...,\n",
       "          2.39754023e-04, 4.11439745e-04, 1.68516402e-04],\n",
       "         [4.87043639e-04, 1.87698941e-04, 3.24552064e-04, ...,\n",
       "          9.94570655e-05, 1.28875472e-04, 1.72582193e-04],\n",
       "         ...,\n",
       "         [5.47358533e-04, 9.88270738e-04, 1.89561921e-04, ...,\n",
       "          2.52065627e-04, 2.94135127e-04, 1.18269847e-04],\n",
       "         [2.41615940e-04, 2.00292794e-04, 2.46891694e-04, ...,\n",
       "          4.49921819e-04, 4.84265795e-04, 1.22728758e-04],\n",
       "         [1.59847885e-04, 2.34211067e-04, 1.69283885e-04, ...,\n",
       "          1.60412150e-04, 1.40661577e-04, 1.05840278e-04]]], dtype=float32)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_ground_truth(None,global_vars['cases']['local_pcn_100'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_case(case_name, case_config):\n",
    "    # load data\n",
    "    print(f'process case {case_name}')\n",
    "    df = pd.read_pickle(case_config['metric_file'])\n",
    "    \n",
    "    # only work on test data.\n",
    "    df = df.xs('test', level='subset')\n",
    "    \n",
    "    \n",
    "    # collect neurons top ranked and worst ranked under various measures.\n",
    "    # I will use of two: mse, and avg(mse, cc, cc2)\n",
    "    # this part is easy to config.\n",
    "    \n",
    "    neuron_ranking_info = None\n",
    "    \n",
    "    \n",
    "    \n",
    "    # load relevance ground truth data, such as neural response,\n",
    "    # mask of each network (averaged across different circles),\n",
    "    # (not upsampled yet)\n",
    "    gt_dict = load_ground_truth(case_name, case_config)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # for each ranking mode,\n",
    "    # then plot.\n",
    "    \n",
    "    # I will calculate everything,\n",
    "    # but visualize top 10 neurons, bottom 10 neurons.\n",
    "    #\n",
    "    # for each neuron, I show\n",
    "    #  0) image mask.\n",
    "    #  1) the best responding images over all 8K images\n",
    "    #  2) response distribution over all data\n",
    "    #  3) top 20 images that contribute most to recurrence, and response improvement\n",
    "    #  4) top 20 images that contribute least to recurrence, and response improvement\n",
    "    #  \n",
    "    # all the visualization is done on an area centered around mask and covers 90% of the energy in the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
