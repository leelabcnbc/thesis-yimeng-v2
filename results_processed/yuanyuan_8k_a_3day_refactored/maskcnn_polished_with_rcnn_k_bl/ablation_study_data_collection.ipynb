{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this report generates all plots for ablation study.\n",
    "\n",
    "\n",
    "there are four sets of data to read\n",
    "\n",
    "1. original recurrent models, 2L, 16/32 ch, average depth as well as performance.\n",
    "2. multipath models, 2L, 16/32 ch, average depth as well as performance.\n",
    "3. ablated multipath models, onlyDX, 2L, 16/32 ch, average depth as well as performance.\n",
    "4. ablated multipath models, leDX/geDX, 2L, 16/32 ch, average depth as well as performance.\n",
    "\n",
    "I should denote them with different colors.\n",
    "\n",
    "\n",
    "I should plot data at two levels.\n",
    "\n",
    "1. overall level\n",
    "2. per read out type. this is to show that 8K data does not work well with \"single path does not work\" hypothesis\n",
    "\n",
    "\n",
    "storage format.\n",
    "\n",
    "a big dataframe\n",
    "\n",
    "* `data_source`: 'original', 'multipath', 'onlyDX'. 'leDXgeDX'\n",
    "* `aggregate_level`: '', 'readout_type=inst-avg', 'readout_type=inst-last', 'readout_type=cm-avg', 'readout_type=cm-last'\n",
    "    * '' means everything\n",
    "    * more general, it's `/` joined by `k=v`\n",
    "* `rcnn_bl_cls`: 2,3,4,5,6,7\n",
    "    * no feed-forward models involved\n",
    "* `n`: how many raw models are involved to get every number that follows\n",
    "* `depth_scalar_mean`: a list of depths.\n",
    "    * for `leDX/geDX`, this will be a proper list, with 2*`rcnn_bl_cls` numbers, following the order in plots in `/results_processed/tang_refactored/maskcnn_polished_with_rcnn_k_bl/20201218_plot.ipynb`\n",
    "    * for others, this will be a list with a single number.\n",
    "* `depth_scalar_sem`: similar to above, but sem. calculated with `sem(ddof=0)`.\n",
    "* `cc2_normed_avg_mean`: similar to `depth_scalar_mean`\n",
    "* `cc2_normed_avg_sem`: similar to `depth_scalar_sem`\n",
    "\n",
    "\n",
    "Note that, for every combination of (`data_source`, `aggregate_level`, `rcnn_bl_cls`), the `n` should be the same and only and all models that are available in `multipath` should be analzyed. This is because `multipath` models have the most demanding requirement on memory so there are fewest of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from os import makedirs\n",
    "from thesis_v2 import dir_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis_v2.analysis.ablation_study import collect_all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_original_perf():\n",
    "    # this does not contain 48, 64 channel results, though.\n",
    "    # (I forgot to train these models in ensemble mode)\n",
    "    f_main_result_perf = join(dir_dict['analyses'], 'yuanyuan_8k_a_3day_refactored', '20200725+20200801+20200801_2', 'main_result.pkl')\n",
    "    df_main_result_perf = pd.read_pickle(f_main_result_perf).sort_index()\n",
    "    \n",
    "    return df_main_result_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_original_depth():\n",
    "    # this does not contain 48, 64 channel results, though.\n",
    "    # (I forgot to train these models in ensemble mode)\n",
    "    f_main_result = join(dir_dict['analyses'], 'yuanyuan_8k_a_3day_refactored', '20200725+20200801+20200801_2', 'source_analysis.pkl')\n",
    "    df_main_result = pd.read_pickle(f_main_result).sort_index()\n",
    "    return df_main_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_multipath_perf():\n",
    "    ret = pd.concat(\n",
    "        [\n",
    "            pd.read_pickle(join(dir_dict['analyses'], 'yuanyuan_8k_a_3day_refactored', '20201118', 'main_result_separatebn.pkl')),\n",
    "            pd.read_pickle(join(dir_dict['analyses'], 'yuanyuan_8k_a_3day_refactored', '20201114', 'main_result_separatebn.pkl')),\n",
    "        ], axis=0\n",
    "    )\n",
    "    return ret\n",
    "\n",
    "def load_multipath_depth():\n",
    "    ret = pd.read_pickle(join(dir_dict['analyses'], 'yuanyuan_8k_a_3day_refactored', '20201114+20201118_separatebn', 'source_analysis.pkl'))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_onlyDX_perf():\n",
    "    ret = pd.concat(\n",
    "        [\n",
    "            pd.read_pickle(join(dir_dict['analyses'], 'yuanyuan_8k_a_3day_refactored', '20201221', 'main.pkl')),\n",
    "        ], axis=0\n",
    "    )\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_onlyDX_depth():\n",
    "    ret = pd.read_pickle(join(dir_dict['analyses'], 'yuanyuan_8k_a_3day_refactored', '20201221', 'source_analysis.pkl'))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_leDXgeDX_perf():\n",
    "    ret = pd.concat(\n",
    "        [\n",
    "            pd.read_pickle(join(dir_dict['analyses'], 'yuanyuan_8k_a_3day_refactored', '20201205+20201205_2', 'main.pkl')),\n",
    "            pd.read_pickle(join(dir_dict['analyses'], 'yuanyuan_8k_a_3day_refactored', '20201213+20201213_2', 'main.pkl')),    \n",
    "        ], axis=0\n",
    "    )\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_leDXgeDX_depth():\n",
    "    f_main_result_src = join(dir_dict['analyses'], 'yuanyuan_8k_a_3day_refactored', '20201205+20201205_2', 'source_analysis.pkl')\n",
    "    f_main_result_2_src = join(dir_dict['analyses'], 'yuanyuan_8k_a_3day_refactored', '20201213+20201213_2', 'source_analysis.pkl')\n",
    "    \n",
    "    df_main_result_src = pd.read_pickle(f_main_result_src)\n",
    "    df_main_result_2_src = pd.read_pickle(f_main_result_2_src)\n",
    "    \n",
    "    df_main_result_src = pd.concat([df_main_result_src, df_main_result_2_src], axis=0).sort_index()\n",
    "    assert df_main_result_src.index.is_unique\n",
    "    \n",
    "    return df_main_result_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(736,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(24,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(24,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(24,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(24,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(96,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(24,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(24,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(24,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(24,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(96,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(24,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(24,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(24,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(24,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(96,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(24,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(24,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(24,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(32,)\n",
      "(24,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(96,)\n"
     ]
    }
   ],
   "source": [
    "collect_all_data(\n",
    "data_loader_dict = {\n",
    "    'multipath': {\n",
    "        'perf': load_multipath_perf,\n",
    "        'depth': load_multipath_depth,\n",
    "    },\n",
    "    'original': {\n",
    "        'perf': load_original_perf,\n",
    "        'depth': load_original_depth,\n",
    "    },\n",
    "    'onlyDX': {\n",
    "        'perf': load_onlyDX_perf,\n",
    "        'depth': load_onlyDX_depth,\n",
    "    },\n",
    "    'leDXgeDX': {\n",
    "        'perf': load_leDXgeDX_perf,\n",
    "        'depth': load_leDXgeDX_depth,\n",
    "    }\n",
    "},\n",
    "    train_keep=5120,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
